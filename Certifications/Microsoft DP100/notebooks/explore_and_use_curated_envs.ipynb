{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4dfdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script found at: c:\\Users\\edmar\\MeusProjetos\\Data_Science\\Certifications\\Microsoft DP100\\create_infra.sh\n",
      "Python: Iniciando deploy para mlw-dp100-labs...\n",
      "Erro: O script shell falhou com código 127.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edmar\\MeusProjetos\\Data_Science\\Certifications\\Microsoft DP100\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3709: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from json import load\n",
    "from re import sub\n",
    "\n",
    "from pathlib import Path\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\n",
    "    r\"C:\\Users\\edmar\\MeusProjetos\\Data_Science\\Certifications\\Microsoft DP100\\.env\"\n",
    ")  # Carrega variáveis de ambiente do arquivo .env\n",
    "\n",
    "\n",
    "def deploy_infrastructure(rg_name, ws_name, location):\n",
    "    \"\"\"\n",
    "    Chama o script shell para criar a infraestrutura no Azure.\n",
    "    \"\"\"\n",
    "    script_path = os.path.abspath(\"../create_infra.sh\")\n",
    "    if os.path.exists(script_path):\n",
    "        print(f\"Script found at: {script_path}\")\n",
    "    else:\n",
    "        print(f\"Error: Script not found at {script_path}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Python: Iniciando deploy para {ws_name}...\")\n",
    "\n",
    "    try:\n",
    "        # Chama o script shell passando os argumentos\n",
    "        # check=True lança uma exceção se o script shell falhar\n",
    "        subprocess.run(\n",
    "            [\"bash\", script_path, rg_name, ws_name, location], check=True, text=True\n",
    "        )\n",
    "        print(\"Python: Deploy finalizado com sucesso!\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Erro: O script shell falhou com código {e.returncode}.\")\n",
    "        sys.exit(1)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: O arquivo '{script_path}' não foi encontrado.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "rg = os.getenv(\"RESOURCE_GROUP\")\n",
    "ws = os.getenv(\"WORKSPACE_NAME\")\n",
    "lc = os.getenv(\"LOCATION\")\n",
    "\n",
    "\n",
    "deploy_infrastructure(rg, ws, lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72cb94f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao workspace: mlw-dp100-labs\n"
     ]
    }
   ],
   "source": [
    "# 1. Autenticação (Usa login do az cli localmente ou Managed Identity na nuvem)\n",
    "credential = DefaultAzureCredential()\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\")\n",
    "location = os.getenv(\"LOCATION\")\n",
    "\n",
    "# 2. Conectar ao Workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group_name=resource_group,\n",
    "    workspace_name=workspace_name,\n",
    ")\n",
    "\n",
    "print(f\"Conectado ao workspace: {ml_client.workspace_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932cb964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have a cluster named aml-cluster, we'll reuse it as is.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# Name assigned to the compute cluster\n",
    "cpu_compute_target = \"aml-cluster\"\n",
    "\n",
    "try:\n",
    "    # let's see if the compute target already exists\n",
    "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
    "    print(\n",
    "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
    "    )\n",
    "\n",
    "except Exception:\n",
    "    print(\"Creating a new cpu compute target...\")\n",
    "\n",
    "    # Let's create the Azure ML compute object with the intended parameters\n",
    "    cpu_cluster = AmlCompute(\n",
    "        name=cpu_compute_target,\n",
    "        # Azure ML Compute is the on-demand VM service\n",
    "        type=\"amlcompute\",\n",
    "        # VM Family\n",
    "        size=\"STANDARD_DS11_V2\",\n",
    "        # Minimum running nodes when there is no job running\n",
    "        min_instances=0,\n",
    "        # Nodes in cluster\n",
    "        max_instances=1,\n",
    "        # How many seconds will the node running after the job termination\n",
    "        idle_time_before_scale_down=120,\n",
    "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "\n",
    "    # Now, we pass the object to MLClient's create_or_update method\n",
    "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84743ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMLCompute with name aml-cluster has a maximum of 1 nodes\n"
     ]
    }
   ],
   "source": [
    "cpu_cluster = ml_client.compute.get(\"aml-cluster\")\n",
    "\n",
    "print(\n",
    "    f\"AMLCompute with name {cpu_cluster.name} has a maximum of {cpu_cluster.max_instances} nodes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeedde8",
   "metadata": {},
   "source": [
    "## Create a script to train a model\n",
    "\n",
    "To train a model, you'll first create the **training_with_cluster.py** script in this directory. The script uses the **diabetes.csv** file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5bf7ac",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv(\n",
    "    r\"C:\\Users\\edmar\\MeusProjetos\\Data_Science\\Certifications\\Microsoft DP100\\azure-ml-labs\\Labs\\04\\src\\diabetes.csv\"\n",
    ")\n",
    "\n",
    "# separate features and labels\n",
    "X, y = (\n",
    "    diabetes[\n",
    "        [\n",
    "            \"Pregnancies\",\n",
    "            \"PlasmaGlucose\",\n",
    "            \"DiastolicBloodPressure\",\n",
    "            \"TricepsThickness\",\n",
    "            \"SerumInsulin\",\n",
    "            \"BMI\",\n",
    "            \"DiabetesPedigree\",\n",
    "            \"Age\",\n",
    "        ]\n",
    "    ].values,\n",
    "    diabetes[\"Diabetic\"].values,\n",
    ")\n",
    "\n",
    "# split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=0\n",
    ")\n",
    "\n",
    "# set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model\n",
    "print(\"Training a logistic regression model with regularization rate of\", reg)\n",
    "model = LogisticRegression(C=1 / reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_scores[:, 1])\n",
    "print(\"AUC: \" + str(auc))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343af5b",
   "metadata": {},
   "source": [
    "## Run a job on a compute cluster\n",
    "\n",
    "Now, you're ready to run the job on the compute cluster you created.\n",
    "\n",
    "> **Note**:\n",
    "> The job will take some time to start as the compute cluster will need to scale from zero to one node. Once the compute cluster is ready, the script will be run. When the job has finished, the compute cluster will scale back down to zero nodes. You can review the compute cluster's status in the **Compute** page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d88c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading src (0.53 MBs): 100%|##########| 529108/529108 [00:01<00:00, 333428.41it/s]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/joyful_rail_slcyc90vmb?wsid=/subscriptions/534bbb2d-e11d-400a-86cf-17d823e7e559/resourcegroups/azure-machine-learning-path/workspaces/mlw-dp100-labs&tid=86b31d04-0222-4e0f-adb6-c46fdd36e439\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"../src\",\n",
    "    command=\"python training_with_cluster.py\",\n",
    "    environment=\"AzureML-sklearn-1.5@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-cluster\",\n",
    "    experiment_name=\"diabetes-training\",\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562af6f",
   "metadata": {},
   "source": [
    "## Agora utilizando Environments:\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013cff31",
   "metadata": {},
   "source": [
    "Note that all curated environments have names that begin **AzureML-** (you can't use this prefix for your own environments).\n",
    "\n",
    "To review a specific environment, you can retrieve an environment by its name and version. For example, you can retrieve the *description* and *tags* of the curated environment you used for the previous job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ff2cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n"
     ]
    }
   ],
   "source": [
    "envs = ml_client.environments.list()\n",
    "for env in envs:\n",
    "    print(env.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99f7813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended environment for Deep Learning in public preview with PyTorch on Azure containing the Azure ML SDK with the latest compatible versions of Ubuntu, Python, PyTorch, CUDA\\RocM, combined with optimizers like ORT Training,+DeepSpeed+MSCCL+ORT MoE and more. {'PyTorch': '1.13.0', 'GPU': 'Cuda11', 'OS': 'Ubuntu20.04', 'Training': ''}\n"
     ]
    }
   ],
   "source": [
    "env = ml_client.environments.get(\"AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\", version=1)\n",
    "print(env.description, env.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b0c01",
   "metadata": {},
   "source": [
    "If a curated environment doesn't include all the Python packages you need to run your script, you can create your own custom environment. By listing all necessary packages in an environment, you can easily re-run your scripts. All the dependencies are stored in the environment which you can then specify in the job configuration, independent of the compute you use.\n",
    "\n",
    "For example, you can create an environment simply from a Docker image. Certain frameworks like PyTorch will have a public Docker image that already includes everything you need. \n",
    "\n",
    "Let's create an environment from a Docker image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61423a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'docker-image-example', 'description': 'Environment created from a Docker image.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/534bbb2d-e11d-400a-86cf-17d823e7e559/resourceGroups/azure-machine-learning-path/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/environments/docker-image-example/versions/1', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\edmar\\\\MeusProjetos\\\\Data_Science\\\\Certifications\\\\Microsoft DP100\\\\notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000002608EE24B00>, 'serialize': <msrest.serialization.Serializer object at 0x000002608EDC7D20>, 'version': '1', 'conda_file': None, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_image = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    name=\"docker-image-example\",\n",
    "    description=\"Environment created from a Docker image.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db4f6864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/brave_ear_ytbyfxnq1b?wsid=/subscriptions/534bbb2d-e11d-400a-86cf-17d823e7e559/resourcegroups/azure-machine-learning-path/workspaces/mlw-dp100-labs&tid=86b31d04-0222-4e0f-adb6-c46fdd36e439\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"../src\",\n",
    "    command=\"python training_with_cluster.py\",\n",
    "    environment=\"docker-image-example:1\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-custom-env\",\n",
    "    experiment_name=\"diabetes-training\",\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ee3b1",
   "metadata": {},
   "source": [
    "The error message will tell you that there is no module named pandas. There are two possible causes for such an error:\n",
    "\n",
    "- The script uses pandas but didn't import the library (`import pandas as pd`). \n",
    "- The script does import the library at the top of the script but the compute didn't have the library installed (`pip install pandas`).\n",
    "\n",
    "After reviewing the `diabetes-training.py` script you can observe the script is correct, which means the library wasn't installed. In other words, the environment didn't include the necessary packages.\n",
    "\n",
    "Let's create a new environment, using the base Docker image used in the previous job. Now, you'll add a conda specification to ensure the necessary packages will be installed. First, run the following cell to create the conda specification file:\n",
    "\n",
    "``` yaml\n",
    "name: basic-env-cpu\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.11\n",
    "  - scikit-learn\n",
    "  - pandas\n",
    "  - numpy\n",
    "  - matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38abfe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'docker-image-plus-conda-example', 'description': 'Environment created from a Docker image plus Conda environment.', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/534bbb2d-e11d-400a-86cf-17d823e7e559/resourceGroups/azure-machine-learning-path/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-labs/environments/docker-image-plus-conda-example/versions/1', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\edmar\\\\MeusProjetos\\\\Data_Science\\\\Certifications\\\\Microsoft DP100\\\\notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000002608ED6D9D0>, 'serialize': <msrest.serialization.Serializer object at 0x000002608D86FD20>, 'version': '1', 'conda_file': {'channels': ['conda-forge'], 'dependencies': ['python=3.11', 'scikit-learn', 'pandas', 'numpy', 'matplotlib'], 'name': 'basic-env-cpu'}, 'build': None, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': '{\\n  \"channels\": [\\n    \"conda-forge\"\\n  ],\\n  \"dependencies\": [\\n    \"python=3.11\",\\n    \"scikit-learn\",\\n    \"pandas\",\\n    \"numpy\",\\n    \"matplotlib\"\\n  ],\\n  \"name\": \"basic-env-cpu\"\\n}'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    conda_file=\"../src/conda-env.yml\",\n",
    "    name=\"docker-image-plus-conda-example\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050ac89",
   "metadata": {},
   "source": [
    "Note that all necessary dependencies are included in the conda specification file for the script to run successfully.\n",
    "\n",
    "Create a new environment using the base Docker image **and** the conda specification file to add the necessary dependencies. Azure Machine Learning will build the conda environment on top of the Docker image you provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "551d0f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading src (0.53 MBs): 100%|##########| 529244/529244 [00:01<00:00, 324495.23it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/bright_tongue_c57mv0n7mv?wsid=/subscriptions/534bbb2d-e11d-400a-86cf-17d823e7e559/resourcegroups/azure-machine-learning-path/workspaces/mlw-dp100-labs&tid=86b31d04-0222-4e0f-adb6-c46fdd36e439\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"../src\",\n",
    "    command=\"python training_with_cluster.py\",\n",
    "    environment=\"docker-image-plus-conda-example:1\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-custom-env\",\n",
    "    experiment_name=\"diabetes-training\",\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e6d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsoft-dp100-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
