{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Sales - Time Series Forecasting\n",
    "---\n",
    "\n",
    "Using machine learning to predict grocery sales\n",
    "\n",
    "In this notebook we will be solving the problem from the competiton: [Store Sales - Time Series Forecasting](https://www.kaggle.com/competitions/store-sales-time-series-forecasting) from [Kaggle](https://www.kaggle.com/)\n",
    "\n",
    "### Summary:\n",
    "*   In this competition, you’ll use time-series forecasting to forecast store sales on data from **Corporación Favorita**, a large Ecuadorian-based grocery retailer.\n",
    "    *   Specifically, you'll build a model that more accurately predicts the unit sales for thousands of items sold at different Favorita stores.  \n",
    "    You'll practice your machine learning skills with an approachable training dataset of dates, store, and item information, promotions, and unit sales.\n",
    "\n",
    "* The evaluation metric for this competition is Root Mean Squared Logarithmic Error - RMSLE.\n",
    "\n",
    "### File Descriptions and Data Field Information\n",
    "\n",
    "#### `train.csv`\n",
    "The training data, comprising time series of features store_nbr, family, and onpromotion as well as the target sales.\n",
    "\n",
    "*   **store_nbr** identifies the store at which the products are sold.\n",
    "*   **family** identifies the type of product sold.\n",
    "*   **sales** gives the total sales for a product family at a particular store at a given date.  \n",
    "    Fractional values are possible since products can be sold in fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\n",
    "*   **onpromotion** gives the total number of items in a product family that were being promoted at a store at a given date.\n",
    "\n",
    "#### `test.csv`\n",
    "The test data, having the same features as the training data.  \n",
    "You will predict the target sales for the dates in this file.  \n",
    "*   The dates in the test data are for the 15 days after the last date in the training data.\n",
    "\n",
    "#### `sample_submission.csv`\n",
    "*   A sample submission file in the correct format.\n",
    "\n",
    "#### `stores.csv`\n",
    "Store metadata, including city, state, type, and cluster.\n",
    "*   **cluster** is a grouping of similar stores.\n",
    "\n",
    "#### `oil.csv`\n",
    "Daily oil price.  \n",
    "Includes values during both the train and test data timeframes. (Ecuador is an oil-dependent country and it's economical health is highly vulnerable to shocks in oil prices.)\n",
    "\n",
    "#### `holidays_events.csv`\n",
    "Holidays and Events, with metadata  \n",
    "\n",
    "\n",
    "### NOTES:\n",
    "Pay special attention to the transferred column.  \n",
    "*   A holiday that is transferred officially falls on that calendar day, but was moved to another date by the government.\n",
    "\n",
    "*   A transferred day is more like a normal day than a holiday. To find the day that it was actually celebrated, look for the corresponding row where type is **Transfer**.  \n",
    "    *   For example, the holiday ***Independencia de Guayaquil*** was transferred from **2012-10-09** to **2012-10-12**, which means it was celebrated on **2012-10-12**.  \n",
    "\n",
    "*   Days that are type **Bridge** are extra days that are added to a holiday (e.g., to extend the break across a long weekend).  \n",
    "\n",
    "*   These are frequently made up by the type **Work Day** which is a day not normally scheduled for work (e.g., Saturday) that is meant to payback the **Bridge**.\n",
    "\n",
    "*   Additional holidays are days added a regular calendar holiday, for example, as typically happens around **Christmas** (making Christmas Eve a holiday).\n",
    "\n",
    "*   Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. **Supermarket sales could be affected by this.**\n",
    "\n",
    "*   A magnitude 7.8 earthquake struck Ecuador on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting file from the `.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_path = Path(\"data/train.csv\")\n",
    "if not file_path.is_file():\n",
    "    with zipfile.ZipFile(\"./store-sales-time-series-forecasting.zip\", 'r') as zf:\n",
    "        zf.extractall(\"./data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the `train.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_path = \"./data/train.csv\"\n",
    "\n",
    "sales = pd.read_csv(\n",
    "    train_path,\n",
    "    usecols=['store_nbr', 'family', 'date', 'sales'],\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'onpromotion': 'uint32',\n",
    "    },\n",
    "    parse_dates=['date']\n",
    "    )\n",
    "\n",
    "sales = sales.set_index('date').to_period('D')\n",
    "sales = sales.set_index(['store_nbr', 'family'], append=True)\n",
    "average_sales = sales.groupby('date').mean()['sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the dataset is composed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = pd.read_csv(\"./data/stores.csv\")\n",
    "\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining some parameters for the plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "plt.rc(\n",
    "    \"figure\",\n",
    "    autolayout=True,\n",
    "    figsize=(11, 4),\n",
    "    titlesize=18,\n",
    "    titleweight='bold',\n",
    ")\n",
    "\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=16,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "plot_params = dict(\n",
    "    color=\"0.75\",\n",
    "    style=\".-\",\n",
    "    markeredgecolor=\"0.25\",\n",
    "    markerfacecolor=\"0.25\",\n",
    "    legend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a graph for the average sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trend = average_sales.rolling(\n",
    "    window=365,\n",
    "    center=True,\n",
    "    min_periods=183,\n",
    ").mean()\n",
    "\n",
    "plot_params = dict(\n",
    "    color=\"0.75\",\n",
    "    style=\".-\",\n",
    "    markeredgecolor=\"0.25\",\n",
    "    markerfacecolor=\"0.25\",\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = average_sales.plot(**plot_params, alpha=0.5)\n",
    "ax = trend.plot(ax=ax, linewidth=3)\n",
    "ax.set_title(\"Average Sales (2013 - 2017)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our first model for TimeSeries\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the model:\n",
    "*   First let's unstack our index, making every index from the MultiIndex became a feature;\n",
    "*   For this model we will use DeterministicProcess from statsmodels\n",
    "*   We will be also using CalendarFourier from statsmodels tsa (Time Series Analysis) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_targets = sales.unstack(['store_nbr', 'family'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first model, let's start using only 1 year -> **2017**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_targets = y_targets.loc['2017']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
    "\n",
    "fourier = CalendarFourier(\n",
    "    freq='M',\n",
    "    order=4\n",
    ")\n",
    "\n",
    "dp = DeterministicProcess(\n",
    "    index=y_targets.index,\n",
    "    constant=True,\n",
    "    order=1,\n",
    "    seasonal=True,\n",
    "    additional_terms=[fourier],\n",
    "    drop=True\n",
    ")\n",
    "\n",
    "X = dp.in_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['NewYear'] = (X.index.dayofyear == 1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y_targets)\n",
    "\n",
    "y_predicted = pd.DataFrame(\n",
    "    data=model.predict(X),\n",
    "    index=X.index,\n",
    "    columns=y_targets.columns\n",
    ")\n",
    "\n",
    "y_predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how or models work for a specified family:\n",
    "*   In this case we will use `family = 'AUTOMOTIVE'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMILY = 'AUTOMOTIVE'\n",
    "STORE = '1'\n",
    "\n",
    "X_forecasted = dp.out_of_sample(30)\n",
    "X_forecasted[\"NewYear\"] = (X_forecasted.index.dayofyear == 1)\n",
    "\n",
    "y_forecasted = pd.DataFrame(\n",
    "    data=model.predict(X_forecasted),\n",
    "    index=X_forecasted.index,\n",
    "    columns=y_targets.columns\n",
    ")\n",
    "\n",
    "ax = y_targets.loc(axis=1)['sales', STORE, FAMILY].plot(**plot_params, label='Sales')\n",
    "ax = y_predicted.loc(axis=1)['sales', STORE, FAMILY].plot(ax=ax, label='Predicted')\n",
    "ax = y_forecasted.loc(axis=1)['sales', STORE, FAMILY].plot(ax=ax, label='Forecasted')\n",
    "ax.set_title(f'{FAMILY} Sales at Store {STORE}')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the first submission to Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    './data/test.csv',\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'onpromotion': 'uint32',\n",
    "    },\n",
    "    parse_dates=['date'],\n",
    ")\n",
    "df_test['date'] = df_test.date.dt.to_period('D')\n",
    "df_test = df_test.set_index(['date', 'store_nbr', 'family',]).sort_index()\n",
    "\n",
    "# Create features for test set\n",
    "X_test = dp.out_of_sample(steps=df_test.index.get_level_values('date').unique().shape[0])\n",
    "X_test.index.name = 'date'\n",
    "X_test['NewYear'] = (X_test.index.dayofyear == 1)\n",
    "\n",
    "\n",
    "y_submit = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y_targets.columns)\n",
    "y_submit = y_submit.stack(['store_nbr', 'family'])\n",
    "y_submit = y_submit.join(df_test['id']).reindex(columns=['id', 'sales'])\n",
    "y_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using time series as features\n",
    "---\n",
    "Some time series properties can only be modeled as serially dependent properties, that is, using as features past values of the target series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagged Series and Lag Plots\n",
    "To investigate possible serial dependence (like cycles) in a time series, we need to create \"lagged\" copies of the series. Lagging a time series means to shift its values forward one or more time steps, or equivalently, to shift the times in its index backward one or more steps. In either case, the effect is that the observations in the lagged series will appear to have happened later in time.\n",
    "\n",
    "This shows the monthly unemployment rate in the US (`y`) together with its first and second lagged series (`y_lag_1` and `y_lag_2`, respectively). Notice how the values of the lagged series are shifted forward in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check if `average sales` has cyclic behavior:\n",
    "\n",
    "average_sales_2017 = average_sales.loc['2017']\n",
    "\n",
    "fourier = CalendarFourier(\n",
    "    freq='M',\n",
    "    order=4\n",
    ")\n",
    "dp = DeterministicProcess(\n",
    "    index=average_sales_2017.index,\n",
    "    constant=True,\n",
    "    order=1,\n",
    "    seasonal=True,\n",
    "    drop=False,\n",
    "    additional_terms=[fourier]\n",
    ")\n",
    "\n",
    "X = dp.in_sample()\n",
    "X['NewYear'] = (X.index.dayofyear == 1)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X, average_sales_2017)\n",
    "\n",
    "average_deseason = average_sales_2017 - model.predict(X)\n",
    "average_deseason.name = 'average_sales_deseasoned'\n",
    "\n",
    "# Moving average\n",
    "moving_avg = average_deseason.rolling(\n",
    "    window=7,\n",
    "    center=True\n",
    ").mean()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "\n",
    "fig.set_size_inches(12, 6)\n",
    "\n",
    "average_deseason.plot(ax=ax1, title='Average Sales 2017 Deseasoned')\n",
    "moving_avg.plot(ax=ax2, title='Moving Average')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the average sales deseasoned and her moving average, we can't see clearly a cyclic behavior.\n",
    "\n",
    "Let's check for a specific Product Family: **SCHOOL AND OFFICE SUPPLIES** and see how it goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\n",
    "    train_path,\n",
    "    usecols=['family', 'date', 'sales', 'onpromotion'],\n",
    "    dtype={\n",
    "        'family': 'category',\n",
    "        'onpromotion': 'uint32',\n",
    "    },\n",
    "    parse_dates=['date']\n",
    "    )\n",
    "\n",
    "family_sales = (\n",
    "    sales\n",
    "    .groupby(['family', 'date'], observed=True)\n",
    "    .mean() \n",
    "    .unstack('family')\n",
    "    .loc['2017', ['sales', 'onpromotion']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ofc_sup_sales_2017 = family_sales.loc(axis=1)[:, 'SCHOOL AND OFFICE SUPPLIES']\n",
    "\n",
    "y = ofc_sup_sales_2017.loc[:, 'sales'].squeeze()\n",
    "\n",
    "fourier = CalendarFourier(\n",
    "    freq='M',\n",
    "    order=4\n",
    ")\n",
    "dp = DeterministicProcess(\n",
    "    index=average_sales_2017.index,\n",
    "    constant=True,\n",
    "    order=1,\n",
    "    seasonal=True,\n",
    "    drop=False,\n",
    "    additional_terms=[fourier]\n",
    ")\n",
    "\n",
    "fourier = CalendarFourier(freq='M', order=4)\n",
    "dp = DeterministicProcess(\n",
    "    constant=True,\n",
    "    index=y.index,\n",
    "    order=1,\n",
    "    seasonal=True,\n",
    "    drop=True,\n",
    "    additional_terms=[fourier],\n",
    ")\n",
    "X_time = dp.in_sample()\n",
    "X_time['NewYearsDay'] = (X_time.index.dayofyear == 1)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X_time, y)\n",
    "y_deseason = y - model.predict(X_time)\n",
    "y_deseason.name = 'sales_deseasoned'\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "fig.set_size_inches(12, 6)\n",
    "\n",
    "y_deseason.plot(ax=ax1)\n",
    "ax1.set_title(\"Sales of School and Office Supplies (deseasonalized)\")\n",
    "\n",
    "y_ma = y.rolling(\n",
    "    window=7,\n",
    "    center=True\n",
    ").mean()\n",
    "\n",
    "y_ma.plot(ax=ax2)\n",
    "ax2.set_title(\"Seven-Day Moving Average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from utils import make_lags, make_leads\n",
    "\n",
    "onpromotion = ofc_sup_sales_2017.loc[:, 'onpromotion'].squeeze().rename('onpromotion')\n",
    "\n",
    "X_lags = make_lags(y_deseason, lags=1)\n",
    "\n",
    "X_promo = pd.concat([\n",
    "    make_lags(onpromotion, lags=1),\n",
    "    onpromotion,\n",
    "    make_leads(onpromotion, leads=1)\n",
    "], axis=1)\n",
    "\n",
    "X = pd.concat([X_lags, X_promo], axis=1)\n",
    "y, X = y.align(X, join='inner')\n",
    "\n",
    "X = X.fillna(0.0)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=30, shuffle=False)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
    "y_fit = pd.Series(model.predict(X_train), index=X_train.index).clip(0.0)\n",
    "y_pred = pd.Series(model.predict(X_valid), index=X_valid.index).clip(0.0)\n",
    "\n",
    "rmsle_train = mean_squared_log_error(y_train, y_fit)**0.5\n",
    "rmsle_valid = mean_squared_log_error(y_valid, y_pred)**0.5\n",
    "print(f'Training RMSLE: {rmsle_train:.5f}')\n",
    "print(f'Validation RMSLE: {rmsle_valid:.5f}')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = y.plot(**plot_params, alpha=0.5, title=\"Onpromotion Average Sales\", ylabel=\"items sold\")\n",
    "ax = y_fit.plot(ax=ax, label=\"Fitted\", color='C0')\n",
    "ax = y_pred.plot(ax=ax, label=\"Forecast\", color='C3')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach: Using all data to build a hybrid model\n",
    "---\n",
    "In this second attempt to decrease RMSLE, we will be using all of the Data that were provided for the competition:\n",
    "*   `train.csv`\n",
    "*   `stores.csv`\n",
    "*   `oil.csv`\n",
    "*   `holidays_events.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all libraries we are going to use:\n",
    "import sys\n",
    "sys.path.append('C:/Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle')\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign all files to a variable:\n",
    "sales = pd.read_csv('./data/train.csv', dtype={'date':'str'}, parse_dates=['date'])\n",
    "stores = pd.read_csv('./data/stores.csv')\n",
    "oil = pd.read_csv('./data/oil.csv', dtype={'date':'str'}, parse_dates=['date']).rename(columns={'dcoilwtico':'oil_price'})\n",
    "holidays = pd.read_csv('./data/holidays_events.csv', dtype={'date':'str'}, parse_dates=['date'])\n",
    "\n",
    "train = sales.copy()\n",
    "test = pd.read_csv('./data/test.csv', dtype={'date':'str'}, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oil -> train, test\n",
    "train = pd.merge(train, oil, on='date', how='left')\n",
    "test = pd.merge(test, oil, on='date', how='left')\n",
    "\n",
    "# stores -> train, test\n",
    "train = pd.merge(train, stores, on='store_nbr', how='left')\n",
    "test = pd.merge(test, stores, on='store_nbr', how='left')\n",
    "\n",
    "# Making holidays useful\n",
    "useless_days = (holidays['transferred'] == True) | (holidays['type'] == 'Work Day')\n",
    "tHolidays = holidays.drop(holidays[useless_days].index)\n",
    "tHolidays = tHolidays.drop(['type', 'description', 'transferred'], axis=1)\n",
    "tHolidays['holiday'] = 1\n",
    "tHolidays = tHolidays.drop(tHolidays[tHolidays['date'].duplicated()].index)\n",
    "\n",
    "# Splitting holidays by 'locale' -> Local, Regional, National\n",
    "local_holidays = tHolidays[tHolidays['locale'] == 'Local']\n",
    "regional_holidays = tHolidays[tHolidays['locale'] == 'Regional']\n",
    "national_holidays = tHolidays[tHolidays['locale'] == 'National'].drop(['locale', 'locale_name'], axis=1) \n",
    "\n",
    "# national_holidays -> train, test\n",
    "train = pd.merge(train, national_holidays, on='date', how='left')\n",
    "test = pd.merge(test, national_holidays, on='date', how='left')\n",
    "\n",
    "# regional_holidays -> train, test\n",
    "for date, state in zip(regional_holidays['date'], regional_holidays['locale_name']):\n",
    "    train.loc[(train['date'] == date) & (train['state'] == state), 'holiday'] = 1\n",
    "\n",
    "for date, state in zip(regional_holidays['date'], regional_holidays['locale_name']):\n",
    "    test.loc[(test['date'] == date) & (test['state'] == state), 'holiday'] = 1\n",
    "\n",
    "# local_holidays -> train, test\n",
    "for date, city in zip(local_holidays['date'], local_holidays['locale_name']):\n",
    "    train.loc[(train['date'] == date) & (train['city'] == city), 'holiday'] = 1\n",
    "\n",
    "for date, city in zip(local_holidays['date'], local_holidays['locale_name']):\n",
    "    test.loc[(test['date'] == date) & (test['city'] == city), 'holiday'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in the train set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "date                 0\n",
       "store_nbr            0\n",
       "family               0\n",
       "sales                0\n",
       "onpromotion          0\n",
       "oil_price       928422\n",
       "city                 0\n",
       "state                0\n",
       "type                 0\n",
       "cluster              0\n",
       "holiday        2766390\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in the test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "date               0\n",
       "store_nbr          0\n",
       "family             0\n",
       "onpromotion        0\n",
       "oil_price       7128\n",
       "city               0\n",
       "state              0\n",
       "type               0\n",
       "cluster            0\n",
       "holiday        28446\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Null values in the train set:\")\n",
    "display(train.isnull().sum())\n",
    "\n",
    "print(\"Null values in the test set:\")\n",
    "display(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Using the Dataframe.bfill and Dataframe.ffill methods:\n",
    "\n",
    "    *   `Dataframe.bfill()` method is used to backward fill the missing values in the dataset.  \n",
    "    It will backward fill the `NaN` values that are present in the pandas dataframe.\n",
    "\n",
    "    *   `Dataframe.ffill()` method is used to forward fill the missing values in the dataset.  \n",
    "    It will forward fill the `NaN` values that are present in the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train -> bfill() and ffill()\n",
    "train.loc[:, 'oil_price'] = train['oil_price'].bfill().ffill()\n",
    "\n",
    "# Test -> bfill() and ffill()\n",
    "test.loc[:, 'oil_price'] = test['oil_price'].bfill().ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in the train set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "date                 0\n",
       "store_nbr            0\n",
       "family               0\n",
       "sales                0\n",
       "onpromotion          0\n",
       "oil_price            0\n",
       "city                 0\n",
       "state                0\n",
       "type                 0\n",
       "cluster              0\n",
       "holiday        2766390\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in the test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "date               0\n",
       "store_nbr          0\n",
       "family             0\n",
       "onpromotion        0\n",
       "oil_price          0\n",
       "city               0\n",
       "state              0\n",
       "type               0\n",
       "cluster            0\n",
       "holiday        28446\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Null values in the train set:\")\n",
    "display(train.isnull().sum())\n",
    "\n",
    "print(\"Null values in the test set:\")\n",
    "display(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   For holidays, if the value is `NaN`, we will fill it with `0`, just to avoid problems on our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train -> fillna()\n",
    "train.loc[:, 'holiday'] = train['holiday'].fillna(value=0)\n",
    "\n",
    "# Test -> fillna()\n",
    "test.loc[:, 'holiday'] = test['holiday'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in the train set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "date           0\n",
       "store_nbr      0\n",
       "family         0\n",
       "sales          0\n",
       "onpromotion    0\n",
       "oil_price      0\n",
       "city           0\n",
       "state          0\n",
       "type           0\n",
       "cluster        0\n",
       "holiday        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in the test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "date           0\n",
       "store_nbr      0\n",
       "family         0\n",
       "onpromotion    0\n",
       "oil_price      0\n",
       "city           0\n",
       "state          0\n",
       "type           0\n",
       "cluster        0\n",
       "holiday        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Null values in the train set:\")\n",
    "display(train.isnull().sum())\n",
    "\n",
    "print(\"Null values in the test set:\")\n",
    "display(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   The column called `\"id\"` has the same values of our index, so we can either remove this feature or set it as our new index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train -> set the 'id' feature as index\n",
    "train.set_index('id', inplace=True)\n",
    "\n",
    "# test -> set the 'id' feature as index\n",
    "test.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag Features\n",
    "\n",
    "Lag features are very commom in Time Series problems\n",
    "\n",
    "*   In this project we will be using 3 lag features:\n",
    "   *   7 days;\n",
    "   *   14 days;\n",
    "   *   28 days;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_sales(df, date_column, sales_column, lag_days=1):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[date_column] += pd.Timedelta(days=lag_days)\n",
    "    df_copy.rename(columns={sales_column : f'sales_{lag_days}_days_ago'}, inplace=True)\n",
    "    df_copy = pd.merge(left=df,\n",
    "                       right=df_copy.loc[:, ['store_nbr', 'family', 'date', f'sales_{lag_days}_days_ago']],\n",
    "                       on=['store_nbr', 'family', 'date'],\n",
    "                       how='left')\n",
    "    df_copy.loc[:, f'sales_{lag_days}_days_ago'].fillna(0, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.concat([train, test])\n",
    "\n",
    "# Train -> Adding lag features for 7, 14 and 28 days:\n",
    "for days in [7, 14, 28]:\n",
    "    train = lag_sales(train, 'date', 'sales', lag_days=days)\n",
    "\n",
    "\n",
    "# creating lag features for the test set, using the last data from de train set\n",
    "for days in [7, 14, 28]:\n",
    "    temp_df = lag_sales(temp_df, 'date', 'sales', lag_days=days)\n",
    "\n",
    "test = temp_df.loc[temp_df['date'] >= test['date'].min(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering:\n",
    "\n",
    "*   Let's create some features that will help us explain some behaviors of our data\n",
    "    *   For that we will be using a custom method called `add_datepart()` from a custom module I created called `utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
      "C:\\Users/edmar/MeusProjetos/Data_Science/Projects/Kaggle\\utils.py:298: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[targ_pre + n] = getattr(fld.dt, n.lower())\n"
     ]
    }
   ],
   "source": [
    "# Train -> Feature Engineering\n",
    "train = utils.add_datepart(df=train, fldnames='date')\n",
    "\n",
    "# Test -> Feature Engineering\n",
    "test = utils.add_datepart(df=test, fldnames='date')\n",
    "\n",
    "# This methods executes inplace, so theres no need to do \"train/test = utils.add_datepart(...)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Sales Feature\n",
    "\n",
    "Let's create a feature that computes the average sales, considering:\n",
    "*   Store: For that we will use `store_nbr`\n",
    "*   Family: The family of products -> `family`\n",
    "*   Day of the week: From the feature `Dayofweek`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = train.groupby(['store_nbr', 'family', 'Dayofweek'])['sales'].mean().reset_index()\n",
    "grouped_df.rename(columns={'sales' : 'avg_sales'}, inplace=True)\n",
    "train = train.merge(right= grouped_df,\n",
    "                    on=['store_nbr', 'family', 'Dayofweek'],\n",
    "                    how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000888 entries, 0 to 3000887\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   store_nbr          int64  \n",
      " 1   family             object \n",
      " 2   sales              float64\n",
      " 3   onpromotion        int64  \n",
      " 4   oil_price          float64\n",
      " 5   city               object \n",
      " 6   state              object \n",
      " 7   type               object \n",
      " 8   cluster            int64  \n",
      " 9   holiday            float64\n",
      " 10  sales_7_days_ago   float64\n",
      " 11  sales_14_days_ago  float64\n",
      " 12  sales_28_days_ago  float64\n",
      " 13  Year               int32  \n",
      " 14  Month              int32  \n",
      " 15  Day                int32  \n",
      " 16  Dayofweek          int32  \n",
      " 17  Dayofyear          int32  \n",
      " 18  Is_month_end       bool   \n",
      " 19  Is_month_start     bool   \n",
      " 20  Is_quarter_end     bool   \n",
      " 21  Is_quarter_start   bool   \n",
      " 22  Is_year_end        bool   \n",
      " 23  Is_year_start      bool   \n",
      " 24  avg_sales          float64\n",
      "dtypes: bool(6), float64(7), int32(5), int64(3), object(4)\n",
      "memory usage: 394.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Now, we should remove useless columns that won't add useful information to our model, such as:\n",
    "    *   `city`: We used the city and state feature to create our `'holiday'` feature, so we no longer need these feature.\n",
    "    *   `state`: Same as above.\n",
    "    *   `cluster`: This feature is about which store cluster the respective store belongs to, which is almost useless to our model.\n",
    "    *   `store_nbr`: Similar to the above feature, it only tells us the identifier to a certain store, which is almost useless to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train -> drop useless features\n",
    "#train = train.drop(['city', 'state', 'cluster', 'store_nbr'], axis=1)\n",
    "\n",
    "# Test -> drop useless features\n",
    "#test = test.drop(['city', 'state', 'cluster', 'store_nbr'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model:\n",
    "---\n",
    "We will use a validation set, consisting of:\n",
    "*   The last 15 days of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehot__family_AUTOMOTIVE</th>\n",
       "      <th>onehot__family_BABY CARE</th>\n",
       "      <th>onehot__family_BEAUTY</th>\n",
       "      <th>onehot__family_BEVERAGES</th>\n",
       "      <th>onehot__family_BOOKS</th>\n",
       "      <th>onehot__family_BREAD/BAKERY</th>\n",
       "      <th>onehot__family_CELEBRATION</th>\n",
       "      <th>onehot__family_CLEANING</th>\n",
       "      <th>onehot__family_DAIRY</th>\n",
       "      <th>onehot__family_DELI</th>\n",
       "      <th>...</th>\n",
       "      <th>onehot__state_Pastaza</th>\n",
       "      <th>onehot__state_Pichincha</th>\n",
       "      <th>onehot__state_Santa Elena</th>\n",
       "      <th>onehot__state_Santo Domingo de los Tsachilas</th>\n",
       "      <th>onehot__state_Tungurahua</th>\n",
       "      <th>onehot__type_A</th>\n",
       "      <th>onehot__type_B</th>\n",
       "      <th>onehot__type_C</th>\n",
       "      <th>onehot__type_D</th>\n",
       "      <th>onehot__type_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   onehot__family_AUTOMOTIVE  onehot__family_BABY CARE  onehot__family_BEAUTY  \\\n",
       "0                          1                         0                      0   \n",
       "1                          0                         1                      0   \n",
       "2                          0                         0                      1   \n",
       "3                          0                         0                      0   \n",
       "4                          0                         0                      0   \n",
       "\n",
       "   onehot__family_BEVERAGES  onehot__family_BOOKS  \\\n",
       "0                         0                     0   \n",
       "1                         0                     0   \n",
       "2                         0                     0   \n",
       "3                         1                     0   \n",
       "4                         0                     1   \n",
       "\n",
       "   onehot__family_BREAD/BAKERY  onehot__family_CELEBRATION  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "\n",
       "   onehot__family_CLEANING  onehot__family_DAIRY  onehot__family_DELI  ...  \\\n",
       "0                        0                     0                    0  ...   \n",
       "1                        0                     0                    0  ...   \n",
       "2                        0                     0                    0  ...   \n",
       "3                        0                     0                    0  ...   \n",
       "4                        0                     0                    0  ...   \n",
       "\n",
       "   onehot__state_Pastaza  onehot__state_Pichincha  onehot__state_Santa Elena  \\\n",
       "0                      0                        1                          0   \n",
       "1                      0                        1                          0   \n",
       "2                      0                        1                          0   \n",
       "3                      0                        1                          0   \n",
       "4                      0                        1                          0   \n",
       "\n",
       "   onehot__state_Santo Domingo de los Tsachilas  onehot__state_Tungurahua  \\\n",
       "0                                             0                         0   \n",
       "1                                             0                         0   \n",
       "2                                             0                         0   \n",
       "3                                             0                         0   \n",
       "4                                             0                         0   \n",
       "\n",
       "   onehot__type_A  onehot__type_B  onehot__type_C  onehot__type_D  \\\n",
       "0               0               0               0               1   \n",
       "1               0               0               0               1   \n",
       "2               0               0               0               1   \n",
       "3               0               0               0               1   \n",
       "4               0               0               0               1   \n",
       "\n",
       "   onehot__type_E  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define the column transformer\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse_output=False), train.select_dtypes('object').columns.to_list())\n",
    "    ],\n",
    "    remainder='passthrough'  # Keeps the other columns (not 'object') as is\n",
    ")\n",
    "\n",
    "transformed_df_train = column_transformer.fit_transform(train.select_dtypes('object'))\n",
    "transformed_df_test = column_transformer.transform(test.select_dtypes('object'))\n",
    "\n",
    "new_column_names = column_transformer.get_feature_names_out().tolist()\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "transformed_df_train = pd.DataFrame(transformed_df_train.astype(np.int64), columns=new_column_names)\n",
    "transformed_df_test = pd.DataFrame(transformed_df_test.astype(np.int64), columns=new_column_names)\n",
    "\n",
    "transformed_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train.drop(columns=train.select_dtypes('object').columns.tolist()), transformed_df_train], axis=1)\n",
    "test = pd.concat([test.drop(columns=test.select_dtypes('object').columns.tolist()).reset_index(drop=True), transformed_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>cluster</th>\n",
       "      <th>holiday</th>\n",
       "      <th>sales_7_days_ago</th>\n",
       "      <th>sales_14_days_ago</th>\n",
       "      <th>sales_28_days_ago</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>onehot__state_Pastaza</th>\n",
       "      <th>onehot__state_Pichincha</th>\n",
       "      <th>onehot__state_Santa Elena</th>\n",
       "      <th>onehot__state_Santo Domingo de los Tsachilas</th>\n",
       "      <th>onehot__state_Tungurahua</th>\n",
       "      <th>onehot__type_A</th>\n",
       "      <th>onehot__type_B</th>\n",
       "      <th>onehot__type_C</th>\n",
       "      <th>onehot__type_D</th>\n",
       "      <th>onehot__type_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr  sales  onpromotion  oil_price  cluster  holiday  \\\n",
       "0          1    0.0            0      93.14       13      1.0   \n",
       "1          1    0.0            0      93.14       13      1.0   \n",
       "2          1    0.0            0      93.14       13      1.0   \n",
       "3          1    0.0            0      93.14       13      1.0   \n",
       "4          1    0.0            0      93.14       13      1.0   \n",
       "\n",
       "   sales_7_days_ago  sales_14_days_ago  sales_28_days_ago  Year  ...  \\\n",
       "0               0.0                0.0                0.0  2013  ...   \n",
       "1               0.0                0.0                0.0  2013  ...   \n",
       "2               0.0                0.0                0.0  2013  ...   \n",
       "3               0.0                0.0                0.0  2013  ...   \n",
       "4               0.0                0.0                0.0  2013  ...   \n",
       "\n",
       "   onehot__state_Pastaza  onehot__state_Pichincha  onehot__state_Santa Elena  \\\n",
       "0                      0                        1                          0   \n",
       "1                      0                        1                          0   \n",
       "2                      0                        1                          0   \n",
       "3                      0                        1                          0   \n",
       "4                      0                        1                          0   \n",
       "\n",
       "   onehot__state_Santo Domingo de los Tsachilas  onehot__state_Tungurahua  \\\n",
       "0                                             0                         0   \n",
       "1                                             0                         0   \n",
       "2                                             0                         0   \n",
       "3                                             0                         0   \n",
       "4                                             0                         0   \n",
       "\n",
       "   onehot__type_A  onehot__type_B  onehot__type_C  onehot__type_D  \\\n",
       "0               0               0               0               1   \n",
       "1               0               0               0               1   \n",
       "2               0               0               0               1   \n",
       "3               0               0               0               1   \n",
       "4               0               0               0               1   \n",
       "\n",
       "   onehot__type_E  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>cluster</th>\n",
       "      <th>holiday</th>\n",
       "      <th>sales_7_days_ago</th>\n",
       "      <th>sales_14_days_ago</th>\n",
       "      <th>sales_28_days_ago</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>onehot__state_Pastaza</th>\n",
       "      <th>onehot__state_Pichincha</th>\n",
       "      <th>onehot__state_Santa Elena</th>\n",
       "      <th>onehot__state_Santo Domingo de los Tsachilas</th>\n",
       "      <th>onehot__state_Tungurahua</th>\n",
       "      <th>onehot__type_A</th>\n",
       "      <th>onehot__type_B</th>\n",
       "      <th>onehot__type_C</th>\n",
       "      <th>onehot__type_D</th>\n",
       "      <th>onehot__type_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>46.8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2311.0</td>\n",
       "      <td>2645.0</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr  sales  onpromotion  oil_price  cluster  holiday  \\\n",
       "0          1    NaN            0       46.8       13      0.0   \n",
       "1          1    NaN            0       46.8       13      0.0   \n",
       "2          1    NaN            2       46.8       13      0.0   \n",
       "3          1    NaN           20       46.8       13      0.0   \n",
       "4          1    NaN            0       46.8       13      0.0   \n",
       "\n",
       "   sales_7_days_ago  sales_14_days_ago  sales_28_days_ago  Year  ...  \\\n",
       "0               7.0                4.0                7.0  2017  ...   \n",
       "1               0.0                0.0                0.0  2017  ...   \n",
       "2               4.0                2.0                3.0  2017  ...   \n",
       "3            2311.0             2645.0             2369.0  2017  ...   \n",
       "4               0.0                0.0                0.0  2017  ...   \n",
       "\n",
       "   onehot__state_Pastaza  onehot__state_Pichincha  onehot__state_Santa Elena  \\\n",
       "0                      0                        1                          0   \n",
       "1                      0                        1                          0   \n",
       "2                      0                        1                          0   \n",
       "3                      0                        1                          0   \n",
       "4                      0                        1                          0   \n",
       "\n",
       "   onehot__state_Santo Domingo de los Tsachilas  onehot__state_Tungurahua  \\\n",
       "0                                             0                         0   \n",
       "1                                             0                         0   \n",
       "2                                             0                         0   \n",
       "3                                             0                         0   \n",
       "4                                             0                         0   \n",
       "\n",
       "   onehot__type_A  onehot__type_B  onehot__type_C  onehot__type_D  \\\n",
       "0               0               0               0               1   \n",
       "1               0               0               0               1   \n",
       "2               0               0               0               1   \n",
       "3               0               0               0               1   \n",
       "4               0               0               0               1   \n",
       "\n",
       "   onehot__type_E  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m val_set \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mloc[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2017-08-01\u001b[39m\u001b[38;5;124m'\u001b[39m, :]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      2\u001b[0m train \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mloc[train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2017-08-01\u001b[39m\u001b[38;5;124m'\u001b[39m, :]\n",
      "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "val_set = train.loc[train['date'] >= '2017-08-01', :].copy()\n",
    "train = train.loc[train['date'] < '2017-08-01', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>cluster</th>\n",
       "      <th>holiday</th>\n",
       "      <th>sales_7_days_ago</th>\n",
       "      <th>sales_14_days_ago</th>\n",
       "      <th>sales_28_days_ago</th>\n",
       "      <th>...</th>\n",
       "      <th>onehot__state_Pastaza</th>\n",
       "      <th>onehot__state_Pichincha</th>\n",
       "      <th>onehot__state_Santa Elena</th>\n",
       "      <th>onehot__state_Santo Domingo de los Tsachilas</th>\n",
       "      <th>onehot__state_Tungurahua</th>\n",
       "      <th>onehot__type_A</th>\n",
       "      <th>onehot__type_B</th>\n",
       "      <th>onehot__type_C</th>\n",
       "      <th>onehot__type_D</th>\n",
       "      <th>onehot__type_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2974158</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0</td>\n",
       "      <td>49.19</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974159</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>49.19</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974160</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0</td>\n",
       "      <td>49.19</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974161</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2627.000</td>\n",
       "      <td>26</td>\n",
       "      <td>49.19</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2438.000</td>\n",
       "      <td>2589.000000</td>\n",
       "      <td>2284.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974162</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>49.19</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000883</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>438.133</td>\n",
       "      <td>0</td>\n",
       "      <td>47.57</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>358.132</td>\n",
       "      <td>570.196000</td>\n",
       "      <td>320.401</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000884</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>154.553</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.954</td>\n",
       "      <td>50.462997</td>\n",
       "      <td>118.927</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000885</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>2419.729</td>\n",
       "      <td>148</td>\n",
       "      <td>47.57</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2299.715</td>\n",
       "      <td>2470.461000</td>\n",
       "      <td>2178.149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000886</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>121.000</td>\n",
       "      <td>8</td>\n",
       "      <td>47.57</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000887</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0</td>\n",
       "      <td>47.57</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.678</td>\n",
       "      <td>19.316000</td>\n",
       "      <td>10.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26730 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store_nbr     sales  onpromotion  oil_price  cluster  \\\n",
       "2974158 2017-08-01          1     5.000            0      49.19       13   \n",
       "2974159 2017-08-01          1     0.000            0      49.19       13   \n",
       "2974160 2017-08-01          1     4.000            0      49.19       13   \n",
       "2974161 2017-08-01          1  2627.000           26      49.19       13   \n",
       "2974162 2017-08-01          1     0.000            0      49.19       13   \n",
       "...            ...        ...       ...          ...        ...      ...   \n",
       "3000883 2017-08-15          9   438.133            0      47.57        6   \n",
       "3000884 2017-08-15          9   154.553            1      47.57        6   \n",
       "3000885 2017-08-15          9  2419.729          148      47.57        6   \n",
       "3000886 2017-08-15          9   121.000            8      47.57        6   \n",
       "3000887 2017-08-15          9    16.000            0      47.57        6   \n",
       "\n",
       "         holiday  sales_7_days_ago  sales_14_days_ago  sales_28_days_ago  ...  \\\n",
       "2974158      0.0            10.000           3.000000              5.000  ...   \n",
       "2974159      0.0             0.000           0.000000              0.000  ...   \n",
       "2974160      0.0             7.000           3.000000              6.000  ...   \n",
       "2974161      0.0          2438.000        2589.000000           2284.000  ...   \n",
       "2974162      0.0             0.000           0.000000              0.000  ...   \n",
       "...          ...               ...                ...                ...  ...   \n",
       "3000883      0.0           358.132         570.196000            320.401  ...   \n",
       "3000884      0.0           112.954          50.462997            118.927  ...   \n",
       "3000885      0.0          2299.715        2470.461000           2178.149  ...   \n",
       "3000886      0.0           170.000         203.000000              0.000  ...   \n",
       "3000887      0.0            15.678          19.316000             10.200  ...   \n",
       "\n",
       "         onehot__state_Pastaza  onehot__state_Pichincha  \\\n",
       "2974158                      0                        1   \n",
       "2974159                      0                        1   \n",
       "2974160                      0                        1   \n",
       "2974161                      0                        1   \n",
       "2974162                      0                        1   \n",
       "...                        ...                      ...   \n",
       "3000883                      0                        1   \n",
       "3000884                      0                        1   \n",
       "3000885                      0                        1   \n",
       "3000886                      0                        1   \n",
       "3000887                      0                        1   \n",
       "\n",
       "         onehot__state_Santa Elena  \\\n",
       "2974158                          0   \n",
       "2974159                          0   \n",
       "2974160                          0   \n",
       "2974161                          0   \n",
       "2974162                          0   \n",
       "...                            ...   \n",
       "3000883                          0   \n",
       "3000884                          0   \n",
       "3000885                          0   \n",
       "3000886                          0   \n",
       "3000887                          0   \n",
       "\n",
       "         onehot__state_Santo Domingo de los Tsachilas  \\\n",
       "2974158                                             0   \n",
       "2974159                                             0   \n",
       "2974160                                             0   \n",
       "2974161                                             0   \n",
       "2974162                                             0   \n",
       "...                                               ...   \n",
       "3000883                                             0   \n",
       "3000884                                             0   \n",
       "3000885                                             0   \n",
       "3000886                                             0   \n",
       "3000887                                             0   \n",
       "\n",
       "         onehot__state_Tungurahua  onehot__type_A  onehot__type_B  \\\n",
       "2974158                         0               0               0   \n",
       "2974159                         0               0               0   \n",
       "2974160                         0               0               0   \n",
       "2974161                         0               0               0   \n",
       "2974162                         0               0               0   \n",
       "...                           ...             ...             ...   \n",
       "3000883                         0               0               1   \n",
       "3000884                         0               0               1   \n",
       "3000885                         0               0               1   \n",
       "3000886                         0               0               1   \n",
       "3000887                         0               0               1   \n",
       "\n",
       "         onehot__type_C  onehot__type_D  onehot__type_E  \n",
       "2974158               0               1               0  \n",
       "2974159               0               1               0  \n",
       "2974160               0               1               0  \n",
       "2974161               0               1               0  \n",
       "2974162               0               1               0  \n",
       "...                 ...             ...             ...  \n",
       "3000883               0               0               0  \n",
       "3000884               0               0               0  \n",
       "3000885               0               0               0  \n",
       "3000886               0               0               0  \n",
       "3000887               0               0               0  \n",
       "\n",
       "[26730 rows x 98 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['date', 'sales'], axis=1)\n",
    "y_train = train.loc[:, 'sales']\n",
    "\n",
    "X_val = val_set.drop(['date', 'sales'], axis=1)\n",
    "y_val = val_set.loc[:, 'sales']\n",
    "\n",
    "X_test = test.drop(['date', 'sales'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA LEAKAGE ALERT:\n",
    "\n",
    "*   As we decided to use a validation set, we need to consider it as something that wasn't seen before, this implies that:\n",
    "    *   In our test set, the lag features for 7 and 14 days should be `NaN`, since those days belongs to the validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, ['sales_7_days_ago', 'sales_14_days_ago',]] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HistGradientBoostingRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(random_state=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(random_state=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(random_state=100)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "hgbr = HistGradientBoostingRegressor(random_state=100)\n",
    "\n",
    "hgbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = hgbr.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Log Error: 0.6165609003943828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "msle = mean_squared_log_error(y_val, y_val_pred)\n",
    "rmsle = np.sqrt(msle)\n",
    "\n",
    "print(f'Root Mean Squared Log Error: {rmsle}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Second Submission to the Competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    './data/test.csv',\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'onpromotion': 'uint32',\n",
    "    },\n",
    "    parse_dates=['date'],\n",
    ")\n",
    "\n",
    "y_submit = pd.DataFrame(hgbr.predict(X_test), index=df_test.id, columns=y_targets.columns)\n",
    "y_submit.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
