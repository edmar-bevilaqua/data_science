{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Njbe8eLcla7"
      },
      "source": [
        "Imports e definição do dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rvXQGAA0ssC",
        "outputId": "c7bde7f3-9ce8-44c3-9724-d4cd028554a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    BatchNormalization,\n",
        "    Input,\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m6C8gisAJqb"
      },
      "source": [
        "O exemplo abaixo mostra as 10 primeiras imagens de treino e teste do MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "JSXB_3_iAMMc",
        "outputId": "2809ba03-9b15-4bfa-edd0-7127b0eae258"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# mostrar as 10 primeiras imagens de treino e teste\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  # treino\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(x_train[i])\n",
        "  plt.title(f\"treino, y={y_train[i]}\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # teste\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(x_test[i])\n",
        "  plt.title(f\"teste, y={y_test[i]}\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_sxNMHZcx2U"
      },
      "source": [
        "A celula abaixo tem a definição de uma rede neural para ser usada no dataset MNIST. Você pode modifica-la como quiser (e.g. adicionar convoluções e/ou mais camadas ocultas) para melhorar o desempenho. Somente não pode modificar o número de neuronios de saida e a métrica de acurácia.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nUBXUukOcKLI"
      },
      "outputs": [],
      "source": [
        "def get_mnist_network():\n",
        "    network = tf.keras.models.Sequential()\n",
        "\n",
        "    network.add(Flatten(input_shape=(28,28)))    # 1 camada de entrada (achatando a entrada pra imagem 28x28 virar um vetor)\n",
        "    network.add(Dense(10, activation=tf.nn.softmax)) # 1 camada de saida com 10 neuronios (1 por classe)\n",
        "\n",
        "    network.compile(\n",
        "        optimizer='sgd',                        # otimizador SGD\n",
        "        loss='sparse_categorical_crossentropy', # entropia cruzada adaptada para multiplas classes\n",
        "        metrics=['accuracy']                    # métrica final de desempenho (nao modifique!)\n",
        "    )\n",
        "\n",
        "    return network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaQ2p_TeN1RE"
      },
      "source": [
        "A celula abaixo tem um exemplo de execucao da rede neural do MNIST naquele dataset. Modifique para executar por 10 épocas e adicione código para medir o tempo gasto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-Z3JZaiNu1h",
        "outputId": "2a65c529-a30d-4f18-e3f5-91d012d216cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 800.0097\n",
            "Epoch 2/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8461 - loss: 137.2368\n",
            "Epoch 3/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 135.3280\n",
            "Epoch 4/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8613 - loss: 116.5559\n",
            "Epoch 5/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8720 - loss: 105.1032\n",
            "Epoch 6/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8587 - loss: 121.3826\n",
            "Epoch 7/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8612 - loss: 135.2253\n",
            "Epoch 8/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8870 - loss: 89.1552\n",
            "Epoch 9/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 154.7707\n",
            "Epoch 10/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 106.6828\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7823 - loss: 152.6513\n",
            "Tempo gasto: 8.55 segundos\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "network = get_mnist_network()                                            # obtem a rede\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()                  # carrega o dataset\n",
        "init = time.time()\n",
        "network.fit(x_train, y_train, epochs=10, batch_size=512)                 # treina a rede\n",
        "end = time.time()\n",
        "loss, accuracy = network.evaluate(x_test, y_test)                        # avalia a rede\n",
        "\n",
        "print(f\"Tempo gasto: {end-init:.2f} segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXQklvZQWZCw"
      },
      "source": [
        "## Tarefa\n",
        "\n",
        "Escreva código para executar redes neurais nos seguintes datasets:\n",
        "- MNIST (pode aproveitar o codigo existente)\n",
        "- Fashion MNIST\n",
        "- CIFAR-10\n",
        "- CIFAR-100\n",
        "\n",
        "Cada execução deve ser por 10 épocas.\n",
        "\n",
        "Você deve preencher as funções a seguir para retornarem a rede neural com a melhor configuração que você conseguiu para cada dataset (a do MNIST deve ser feita na `get_mnist_network()` acima).\n",
        "\n",
        "IMPORTANTE: as funções `get_X_network()` não devem TREINAR nem AVALIAR  a rede neural, apenas instancia-la para o problema X (MNIST, Fashion MNIST, etc) e retorna-las.\n",
        "\n",
        "Ao final, preencha o dict `results` com o desempenho encontrado em cada execução."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DAdzuLJ-HcA8"
      },
      "outputs": [],
      "source": [
        "# classe auxiliar para facilitar a medição do tempo gasto.\n",
        "\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = {}\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "        self.epoch += 1\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times[self.epoch] = (time.time() - self.epoch_time_start)\n",
        "\n",
        "    def _total_time(self):\n",
        "        return sum(self.times.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lX2-RCMm5Yro"
      },
      "outputs": [],
      "source": [
        "def get_mnist_network():\n",
        "    network = tf.keras.models.Sequential()\n",
        "\n",
        "    network.add(Input(shape=(28, 28, 1)))\n",
        "    network.add(Conv2D(16, (3,3), activation='relu')) # 1 camada de convolução: 16 filtros 3x3\n",
        "    network.add(MaxPooling2D((2,2), strides=2)) # max pooling 2x2\n",
        "    network.add(Flatten()) # achatar p/ entrar em MLP\n",
        "    network.add(Dense(20, activation='relu')) # 1 camada oculta\n",
        "    network.add(Dense(10, activation='softmax')) # 1 camada de saida com 10 neuronios\n",
        "\n",
        "    network.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return network\n",
        "\n",
        "def get_fashion_mnist_network():\n",
        "    network = tf.keras.models.Sequential()\n",
        "\n",
        "    network.add(Input(shape=(28, 28, 1)))\n",
        "    network.add(Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    network.add(MaxPooling2D((2,2)))\n",
        "    network.add(Conv2D(64, (3,3), activation='relu'))\n",
        "    network.add(MaxPooling2D((2,2)))\n",
        "    network.add(Flatten())\n",
        "    network.add(Dense(64, activation='relu'))\n",
        "    network.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    network.compile('adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return network\n",
        "\n",
        "def get_cifar10_network():\n",
        "    network = Sequential()\n",
        "\n",
        "    network.add(Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "    network.add(BatchNormalization())\n",
        "    network.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    network.add(BatchNormalization())\n",
        "    network.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    network.add(Dropout(0.25))\n",
        "\n",
        "    network.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    network.add(BatchNormalization())\n",
        "    network.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    network.add(BatchNormalization())\n",
        "    network.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    network.add(Dropout(0.35))\n",
        "\n",
        "    network.add(Flatten())\n",
        "    network.add(Dense(512, activation='relu'))\n",
        "    network.add(Dropout(0.5))\n",
        "    network.add(Dense(10, activation='softmax'))\n",
        "    network.compile(\n",
        "        optimizer= Adam(learning_rate = 0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    return network\n",
        "\n",
        "def get_cifar100_network():\n",
        "    network = tf.keras.models.Sequential()\n",
        "\n",
        "    network.add(Input(shape=(32, 32, 3)))\n",
        "    network.add(Conv2D(16, (3,3), activation='relu')) # 1 camada de convolução: 16 filtros 3x3\n",
        "    network.add(MaxPooling2D((2,2), strides=2)) # max pooling 2x2\n",
        "    network.add(Flatten()) # achatar p/ entrar em MLP\n",
        "    network.add(Dense(60, activation='relu')) # 1 camada oculta\n",
        "    network.add(Dense(100, activation='softmax')) # 1 camada de saida com 100 neuronios\n",
        "\n",
        "    network.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "e_Vqurl0KMme"
      },
      "outputs": [],
      "source": [
        "def train_eval_mnist_pipeline(model, dataset, epochs):\n",
        "    # cria a instância da classe TimeHistory\n",
        "    time_callback = TimeHistory()\n",
        "\n",
        "    # faz o unpack do dataset\n",
        "    (x_train, y_train),(x_test, y_test) = dataset.load_data()\n",
        "\n",
        "    # treina o modelo\n",
        "    model.fit(x_train, y_train, epochs=epochs, batch_size=512, callbacks=[time_callback])\n",
        "\n",
        "    # avalia o modelo\n",
        "    loss, accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "    return {\n",
        "        'loss': loss,\n",
        "        'accuracy' : accuracy,\n",
        "        'time_callbacks' : time_callback\n",
        "    }\n",
        "\n",
        "def train_eval_cifar_pipeline(model, dataset, epochs):\n",
        "    # cria a instância da classe TimeHistory\n",
        "    time_callback = TimeHistory()\n",
        "\n",
        "    # faz o unpack do dataset\n",
        "    (X_train, y_train),(X_test, y_test) = dataset.load_data()\n",
        "\n",
        "    # normaliza os dados\n",
        "    X_train = X_train.astype('float32') / 255.0\n",
        "    X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "    num_classes = len(set(y_train.reshape(-1)))\n",
        "\n",
        "    y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "    y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "    # reduz o LR quando a acurácia para de melhorar\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                    factor=0.5, patience=2,\n",
        "                                    verbose=1, min_lr=1e-5)\n",
        "\n",
        "    # treina o modelo\n",
        "    model.fit(X_train,\n",
        "              y_train,\n",
        "              epochs=epochs,\n",
        "              batch_size=512,\n",
        "              callbacks=[time_callback, lr_scheduler])\n",
        "\n",
        "    # avalia o modelo\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "    return {\n",
        "        'loss': loss,\n",
        "        'accuracy' : accuracy,\n",
        "        'time_callbacks' : time_callback\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoNod3uQNu0P"
      },
      "source": [
        "## MNIST Clássico:\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRpDDVypNG18",
        "outputId": "1eee1974-b8d2-4dd1-8eb3-9d8d57a6ac83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 133ms/step - accuracy: 0.2983 - loss: 5.5715\n",
            "Epoch 2/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - accuracy: 0.6780 - loss: 0.9697\n",
            "Epoch 3/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 121ms/step - accuracy: 0.8110 - loss: 0.5550\n",
            "Epoch 4/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - accuracy: 0.9102 - loss: 0.3157\n",
            "Epoch 5/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 128ms/step - accuracy: 0.9455 - loss: 0.2120\n",
            "Epoch 6/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 121ms/step - accuracy: 0.9534 - loss: 0.1761\n",
            "Epoch 7/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 117ms/step - accuracy: 0.9606 - loss: 0.1470\n",
            "Epoch 8/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - accuracy: 0.9636 - loss: 0.1374\n",
            "Epoch 9/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 129ms/step - accuracy: 0.9682 - loss: 0.1141\n",
            "Epoch 10/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 127ms/step - accuracy: 0.9706 - loss: 0.1042\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9538 - loss: 0.1979\n"
          ]
        }
      ],
      "source": [
        "# dataset\n",
        "mnist_dataset = tf.keras.datasets.mnist\n",
        "\n",
        "# rede neural\n",
        "mnist_network = get_mnist_network()\n",
        "\n",
        "# pipeline de treino e avaliação\n",
        "classic_mnist_results = train_eval_mnist_pipeline(mnist_network, mnist, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9oCE9lKOGqV"
      },
      "source": [
        "## Fashion MNIST:\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCA8zeewOIak",
        "outputId": "329a4d1d-86ca-4f27-af3c-29b111c6b2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m       0/26421880\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 395ms/step - accuracy: 0.5521 - loss: 5.7476\n",
            "Epoch 2/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 390ms/step - accuracy: 0.8332 - loss: 0.4660\n",
            "Epoch 3/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 401ms/step - accuracy: 0.8565 - loss: 0.3987\n",
            "Epoch 4/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 438ms/step - accuracy: 0.8717 - loss: 0.3515\n",
            "Epoch 5/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 425ms/step - accuracy: 0.8818 - loss: 0.3267\n",
            "Epoch 6/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 455ms/step - accuracy: 0.8858 - loss: 0.3057\n",
            "Epoch 7/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 414ms/step - accuracy: 0.8971 - loss: 0.2823\n",
            "Epoch 8/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 399ms/step - accuracy: 0.9024 - loss: 0.2642\n",
            "Epoch 9/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 428ms/step - accuracy: 0.9039 - loss: 0.2557\n",
            "Epoch 10/10\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 439ms/step - accuracy: 0.9124 - loss: 0.2394\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8745 - loss: 0.3568\n"
          ]
        }
      ],
      "source": [
        "# dataset\n",
        "fashion_mnist_dataset = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "# rede neural\n",
        "fashion_mnist_network = get_fashion_mnist_network()\n",
        "\n",
        "# pipeline de treino e avaliação\n",
        "fashion_results = train_eval_mnist_pipeline(fashion_mnist_network, fashion_mnist_dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyZYw_2PRAi1"
      },
      "source": [
        "## CIFAR-10\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzYmONoRRG6M",
        "outputId": "4226e15f-affc-4f2e-cb91-28c8dc1a5302"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m783s\u001b[0m 8s/step - accuracy: 0.3084 - loss: 2.6752 - learning_rate: 0.0010\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py:145: UserWarning: Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss,learning_rate.\n",
            "  callback.on_epoch_end(epoch, logs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 8s/step - accuracy: 0.5153 - loss: 1.3485 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 8s/step - accuracy: 0.5999 - loss: 1.1210 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 8s/step - accuracy: 0.6676 - loss: 0.9377 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m822s\u001b[0m 8s/step - accuracy: 0.7082 - loss: 0.8248 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m812s\u001b[0m 8s/step - accuracy: 0.7375 - loss: 0.7407 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 8s/step - accuracy: 0.7584 - loss: 0.6849 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m846s\u001b[0m 8s/step - accuracy: 0.7800 - loss: 0.6270 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m806s\u001b[0m 8s/step - accuracy: 0.7940 - loss: 0.5807 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m786s\u001b[0m 8s/step - accuracy: 0.8121 - loss: 0.5315 - learning_rate: 0.0010\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 131ms/step - accuracy: 0.7933 - loss: 0.6274\n"
          ]
        }
      ],
      "source": [
        "# dataset\n",
        "cifar_10_dataset = tf.keras.datasets.cifar10\n",
        "\n",
        "# rede neural\n",
        "cifar_10_network = get_cifar10_network()\n",
        "\n",
        "# pipeline de treino e avaliação\n",
        "dict_test = train_eval_cifar_pipeline(cifar_10_network, cifar_10_dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRlshxzIRHMD"
      },
      "source": [
        "## CIFAR-100\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW3V3LN5RI1E",
        "outputId": "024d94b7-657c-4538-fb67-f6b6909fc414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 207ms/step - accuracy: 0.0271 - loss: 4.5086 - learning_rate: 0.0010\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py:145: UserWarning: Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss,learning_rate.\n",
            "  callback.on_epoch_end(epoch, logs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 218ms/step - accuracy: 0.0944 - loss: 3.9904 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 204ms/step - accuracy: 0.1353 - loss: 3.7416 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 218ms/step - accuracy: 0.1592 - loss: 3.6064 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 228ms/step - accuracy: 0.1798 - loss: 3.4841 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 218ms/step - accuracy: 0.1947 - loss: 3.3896 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 217ms/step - accuracy: 0.2133 - loss: 3.2944 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 203ms/step - accuracy: 0.2223 - loss: 3.2323 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 231ms/step - accuracy: 0.2359 - loss: 3.1598 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 210ms/step - accuracy: 0.2450 - loss: 3.1158 - learning_rate: 0.0010\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2371 - loss: 3.1753\n"
          ]
        }
      ],
      "source": [
        "# dataset\n",
        "cifar_100_dataset = tf.keras.datasets.cifar100\n",
        "\n",
        "# rede neural\n",
        "cifar_100_network = get_cifar100_network()\n",
        "\n",
        "# pipeline de treino e avaliação\n",
        "cifar100_results = train_eval_cifar_pipeline(cifar_100_network, cifar_100_dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi7K43VRE3Jn",
        "outputId": "58ef784a-abb7-4f1f-bc21-1e9da08902d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "309.0502562522888"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dict_test['time_callbacks']._total_time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozwIAkarPXPo"
      },
      "source": [
        "Preencha o dict abaixo substituindo os None com a acuracia final (acc) e o tempo de treinamento (time) encontrado no seu experimento pra cada dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KaDBLRKGbkE",
        "outputId": "306b3cee-8192-4490-dd9c-3a7e27d85d02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 4s - 2ms/step - accuracy: 0.8198 - loss: 0.7730 - val_accuracy: 0.8816 - val_loss: 0.4755\n",
            "Epoch 2/10\n",
            "1875/1875 - 5s - 3ms/step - accuracy: 0.8827 - loss: 0.4538 - val_accuracy: 0.8963 - val_loss: 0.3972\n",
            "Epoch 3/10\n",
            "1875/1875 - 4s - 2ms/step - accuracy: 0.8919 - loss: 0.4019 - val_accuracy: 0.9028 - val_loss: 0.3651\n",
            "Epoch 4/10\n",
            "1875/1875 - 5s - 3ms/step - accuracy: 0.8975 - loss: 0.3759 - val_accuracy: 0.9068 - val_loss: 0.3468\n",
            "Epoch 5/10\n",
            "1875/1875 - 5s - 3ms/step - accuracy: 0.9011 - loss: 0.3594 - val_accuracy: 0.9106 - val_loss: 0.3346\n",
            "Epoch 6/10\n",
            "1875/1875 - 5s - 3ms/step - accuracy: 0.9036 - loss: 0.3479 - val_accuracy: 0.9106 - val_loss: 0.3254\n",
            "Epoch 7/10\n",
            "1875/1875 - 6s - 3ms/step - accuracy: 0.9058 - loss: 0.3390 - val_accuracy: 0.9120 - val_loss: 0.3193\n",
            "Epoch 8/10\n",
            "1875/1875 - 4s - 2ms/step - accuracy: 0.9073 - loss: 0.3320 - val_accuracy: 0.9141 - val_loss: 0.3150\n",
            "Epoch 9/10\n",
            "1875/1875 - 4s - 2ms/step - accuracy: 0.9089 - loss: 0.3261 - val_accuracy: 0.9138 - val_loss: 0.3096\n",
            "Epoch 10/10\n",
            "1875/1875 - 5s - 3ms/step - accuracy: 0.9103 - loss: 0.3213 - val_accuracy: 0.9156 - val_loss: 0.3061\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.3505\n",
            "\n",
            "Acurácia no teste: 0.9156\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Carregar o dataset MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 2. Pré-processamento\n",
        "x_train = x_train / 255.0  # Normaliza para [0,1]\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)  # One-hot encoding\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 3. Definir o modelo (Perceptron simples: sem camadas ocultas)\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),   # Transformar imagem 2D em vetor 1D\n",
        "    Dense(10, activation='softmax')  # Camada de saída com 10 classes\n",
        "])\n",
        "\n",
        "# 4. Compilar\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 5. Treinar por no máximo 10 épocas\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=2)\n",
        "\n",
        "# 6. Avaliar\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"\\nAcurácia no teste: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIPpN21qPWkW"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"mnist\": {\"time\": 182, \"acc\": 0.9625},\n",
        "    \"fashion_mnist\": {\"time\": 659, \"acc\": 0.9584},\n",
        "    \"cifar10\": {\"time\": 8164, \"acc\": 0.7933},\n",
        "    \"cifar100\": {\"time\": 309, \"acc\": 0.2371},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Balt30GsFZGY"
      },
      "source": [
        "## Perguntas:\n",
        "---\n",
        "1) Em quais datasets um perceptron simples (sem convolução e sem camadas ocultas) obtem uma acurácia acima de 80%?\n",
        "* **R**: A partir de tentativa e erro, apenas no dataset do MNIST clássico um perceptron simples foi capaz de atingir acurácia acima de 80%.\n",
        "\n",
        "2) Qual a acurácia máxima obtida no CIFAR-10? Qual modificação teve maior impacto positivo? Qual o maior desafio/dificuldade?\n",
        "* **R**: Utilizando uma rede mais robusta, consegui atingir acurácia de 79.3% no conjunto de teste. A modificação que teve maior impacto foi a normalização dos dados para o intervalo entre 0 e 1. O maior desafio foi conseguir deixar a acurácia maior sem aumentar exponencialmente o tempo de treinamento em 10 épocas.\n",
        "\n",
        "3) Foi possivel obter mais de 60% de acurácia no CIFAR-100? Qual modificação teve maior impacto positivo? Qual o maior desafio/dificuldade?\n",
        "* **R**: Para minhas tentantivas, não. Imagino que, assim como no dataset do CIFAR-10, a normalização dos dados e a utilização de _Batch Normalization_ é crucial para se atingir acurácias superiores a 60%.\n",
        "\n",
        "4) Quais fatores (tanto das próprias redes quanto dos dados) levam as redes neurais a melhorarem o desempenho? E quais fatores tornam o desempenho pior?\n",
        "* **R**: Podemos citar como fatores que melhoram o desempenho das redes:\n",
        "    * Normalização dos dados: Estabilizam mais as redes e tendem a acelerar o treinamento;\n",
        "    * Normalização em lotes (_Batch Normalization_): Também ajudam a estabilizar os dados e a garantir que os gradientes não fiquem muito instáveis durante o treinamento;\n",
        "    * Funções de ativação bem escolhidas: Este é um ponto especial, pois a má escolha da função de ativação pode fazer com que o modelo leve muito mais tempo para ser treinado, além de não garantir uma maior acurácia;\n",
        "    * Taxa de aprendizado bem definida: Ajuda no modelo a convergir de forma mais acelarada e a não ficar preso em mínimos locais, a depender da solução escolhida.\n",
        "    * Quantidade de 'neurônios' por camada: Ajudam na capacidade do modelo de se ajustar a distribuições de dados mais complexas, como é o caso de imagens.\n",
        "    * Camadas Convolucionais: Ajudam na extração de padrões representativos dos dados.\n",
        "    * Autoencoders: Podem ajudar na redução de dimensionalidade e também na redução de ruídos.\n",
        "    * Quanto aos dados, estes também podem contribuir para melhorar o desempenho de um modelo, caso:\n",
        "        * Apresentem um balanceamento das classes, pois ajuda na representativadade de cada classe;\n",
        "        * Tenham poucos ruídos e outliers;\n",
        "        * Apresentem boa diversidade.\n",
        "* Falando agora dos fatores que podem prejudicar os modelos, podemos citar:\n",
        "    * Redes muito rasas: São incapazes de se ajustar a dados mais complexos;\n",
        "    * Taxa de aprendizado mal definida: Pode fazer o modelo demorar muito parar convergir ou então podemo fazer ele dar saltos muito grandes, impossibilitando a convergência.\n",
        "    * Redes extremamente profundas e mal ajustadas: Aprendem tão bem o conjunto de treino que modelam até os ruídos, tendendo a performar muito mal no conjunto de testes.\n",
        "    * Falta de normalizações: Podem deixar a rede muito instável e fazer com que demore demais para treinar.\n",
        "    * Quanto aos dados, estes também podem contribuir para piorar o desempenho de um modelo, caso:\n",
        "        * Apresentem um desbalanceamento das classes, gerando uma dominância da classe predominante e fazendo com que, se mal treinado, faça a rede tender a sempre escolher a classe dominante;\n",
        "        * Tenham muitos ruídos e outliers;\n",
        "        * Apresentem baixa diversidade."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
