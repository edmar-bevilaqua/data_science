{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CMP263 - Aprendizagem de Máquina - INF/UFRGS\n",
        "\n",
        "## Atividade Prática: Árvores de Decisão\n",
        "\n",
        "As árvores de decisão são conhecidas por possuírem um baixo viés, ao mesmo tempo em que apresentam alta variância.\n",
        "Isto é, o método é capaz de modelar fronteiras de decisão bastante complexas, o que, por um lado, é positivo, mas torna o algoritmo bastante suscetível a ruído ou a padrões nos dados de treino que não generalizam para instâncias de teste.\n",
        "Por isso, técnicas de poda são fundamentais para o uso efetivo do modelo em dados novos.\n",
        "\n",
        "Nessa atividade, iremos analisar como a estrutura e as predições da árvore de decisão são afetadas por pequenas variações no conjunto de treino. Além disso, veremos duas técnicas de poda que podem ser usadas para controlar a complexidade do modelo.\n",
        "\n",
        "**Este *colab* deve ser usado como base para o preenchimento do questionário encontrado no Moodle. Faça uma cópia do mesmo para realizar o exercício.** A forma mais fácil para duplicar este *colab* é ir em File > \"Save a Copy in Drive\". Não é necessário entregar este *colab* preenchido, mas guarde-o para caso ache que algum questionário está errado.\n"
      ],
      "metadata": {
        "id": "E650rvooE65t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objetivos da Atividade\n",
        "* Analisar os impactos da característica de **variância** nas árvores de decisão.\n",
        "* Analisar o efeito da **poda** em árvores de decisão.\n"
      ],
      "metadata": {
        "id": "bzW8jdj7Jgp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento dos Dados\n",
        "\n",
        "Além de possuir uma grande quantidade de algoritmos de aprendizado de máquina, a biblioteca [scikit-learn](https://scikit-learn.org/stable/index.html) possui também funções para carregar alguns conjuntos de dados.\n",
        "\n",
        "Nessa seção, vamos usar essas funções para carregar o dataset [Breast Cancer Winconsin](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset). Esse dataset possui um total de 30 atributos relativos a características de tumores de mama e um atributo alvo binário, que indica se o tumor é maligno ou benigno. Todos os 30 atributos são valores reais."
      ],
      "metadata": {
        "id": "owi-J_whK4IS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtenção e análise dos dados\n",
        "O código abaixo carrega o dataset utilizando as funções do scikit-learn e mostra algumas informações básicas sobre os dados"
      ],
      "metadata": {
        "id": "SqJsx9OITVn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # matriz contendo os atributos\n",
        "y = data.target  # vetor contendo a classe (0 para maligno e 1 para benigno) de cada instância\n",
        "feature_names = data.feature_names  # nome de cada atributo\n",
        "target_names = data.target_names  # nome de cada classe\n",
        "\n",
        "print(f\"Dimensões de X: {X.shape}\\n\")\n",
        "print(f\"Dimensões de y: {y.shape}\\n\")\n",
        "print(f\"Nomes dos atributos: {feature_names}\\n\")\n",
        "print(f\"Nomes das classes: {target_names}\")"
      ],
      "metadata": {
        "id": "p-1VZTPjQax2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como pode ser visto, o dataset possui 569 exemplos, sendo cada exemplo constituído por 30 diferentes atributos.\n",
        "\n",
        "### Quantidade de Exemplos de cada Classe\n",
        "É possível também contar quantos exemplos pertencem à classe dos tumores malignos e quantos à classe dos benignos"
      ],
      "metadata": {
        "id": "owFi-RCWQj5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "n_malign = np.sum(y == 0)\n",
        "n_benign = np.sum(y == 1)\n",
        "\n",
        "print(\"Número de exemplos malignos: %d\" % n_malign)\n",
        "print(\"Número de exemplos benignos: %d\" % n_benign)"
      ],
      "metadata": {
        "id": "SRHpI8VXSgZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variância nas Árvores de Decisão\n"
      ],
      "metadata": {
        "id": "60j9N1m-gnf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analisando a Estrutura das Árvores\n",
        "\n",
        "Como estudado em aula, a árvore de decisão é conhecida por ser um classificador com alta variância. Isso possui consequências na estrutura das árvores treinadas.\n",
        "\n",
        "O código abaixo treina várias árvores de decisão com diferentes conjuntos de treino obtidos através do método holdout.\n",
        "Use-o para responder à **Questão 1** do questionário.\n"
      ],
      "metadata": {
        "id": "iMAD6e-vT5I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split  # função do scikit-learn que implementa um holdout\n",
        "\n",
        "\n",
        "def get_root_node(dt, feature_names):\n",
        "    feature_idx = dt.tree_.feature[0]\n",
        "    return feature_names[feature_idx]\n",
        "\n",
        "\n",
        "n_repeats = 20\n",
        "root_nodes = []\n",
        "\n",
        "# variando o seed do holdout, geramos conjuntos de treino e teste um pouco diferentes a cada iteração\n",
        "for split_random_state in range(0, n_repeats):\n",
        "  # Holdout com 20% de dados de teste\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=split_random_state)\n",
        "\n",
        "  # Treinamento da árvore usando os dados de treino\n",
        "  dt = DecisionTreeClassifier(random_state=0)\n",
        "  dt.fit(X_train, y_train)\n",
        "\n",
        "  # Obtemos o atributo usado na raiz e o salvamos na lista\n",
        "  root_node = get_root_node(dt, feature_names)\n",
        "  root_nodes.append(root_node)\n",
        "\n",
        "root_nodes"
      ],
      "metadata": {
        "id": "sWBWbbTIUuQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for node in set(root_nodes):\n",
        "    print(f\"{node}: {root_nodes.count(node)}\")"
      ],
      "metadata": {
        "id": "ivimg9m1nxN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Paea visualizar a estrutura da árvore\n",
        "import graphviz\n",
        "from sklearn import tree\n",
        "\n",
        "dot_data = tree.export_graphviz(dt,\n",
        "                                out_file=None,\n",
        "                                feature_names = feature_names,\n",
        "                                class_names= target_names,\n",
        "                                filled=True)\n",
        "\n",
        "## Plotar a árvore de decisão no notebook\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph\n",
        "\n",
        "## Para salvar como png, descomente as linhas abaixo\n",
        "#graph.format = 'png'\n",
        "#graph.render('DecisionTree1',view = True)"
      ],
      "metadata": {
        "id": "vtSvrYQ721BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise da Variação na Acurácia\n",
        "\n",
        "A propriedade de variância também implica em efeitos na variabilidade do desempenho dos modelos. Para fins de exemplo, podemos usar a acurácia como medida de desempenho através das funções do scikit-learn. Entretanto, outras métricas de desempenho como Recall e Precisão, que são mais indicadas para problemas em que o número de instâncias por classe é desbalanceado (como é o caso deste conjunto de dados) poderiam também ser exploradas (a critério do aluno, podem ser adicionadas para observação, mas a questão deve ser respondida com base na acurácia)."
      ],
      "metadata": {
        "id": "4dE3IWkdlpVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Acurácia nos dados de teste: %.3f\" % accuracy)\n"
      ],
      "metadata": {
        "id": "UHVpl0IipSR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo executa repetidas vezes o treinamento das árvores de decisão, da mesma forma que no item *Analisando a Estrutura das Árvores*.\n",
        "Modifique-o de forma a obter a acurácia para cada execução e então calcule a média, desvio padrão, máximo e mínimo dos valores. Use esses resultados para responder à **Questão 2**.\n",
        "\n",
        "**Atenção: Não mude os valores que estão sendo passados para os parâmetros random_state para garantir a reprodutibilidade do código**.\n"
      ],
      "metadata": {
        "id": "Dp5K0jyaLduN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "n_repeats = 20\n",
        "accuracies = []\n",
        "\n",
        "# variando o seed do holdout, geramos conjuntos de treino e teste um pouco diferentes a cada iteração\n",
        "for split_random_state in range(0, n_repeats):\n",
        "  # Holdout com 20% de dados de teste\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=split_random_state)\n",
        "\n",
        "  # Nova instância da árvore de decisão\n",
        "  dt = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "  # Treine a árvore de decisão usando os dados de treino\n",
        "  dt.fit(X_train, y_train)\n",
        "\n",
        "  # Faça a predição para os dados de teste\n",
        "  y_pred = dt.predict(X_test)\n",
        "\n",
        "  # Calcule a acurácia nos dados de teste\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "  # Salve a acurácia na lista\n",
        "  accuracies.append(accuracy)\n",
        "\n",
        "# Calcule a média, desvio padrão, máximo e mínimo das acurácias (pode usar numpy)\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "max_accuracy = np.max(accuracies)\n",
        "min_accuracy = np.min(accuracies)\n",
        "\n",
        "print(\"Média da acurácia: %.3f\" % mean_accuracy)\n",
        "print(\"Desvio padrão da acurácia: %.3f\" % std_accuracy)\n",
        "print(\"Máximo da acurácia: %.3f\" % max_accuracy)\n",
        "print(\"Mínimo da acurácia: %.3f\" % min_accuracy)"
      ],
      "metadata": {
        "id": "GGNDgUCzl2jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise de Instância individuais\n",
        "\n",
        "1. Treine novamente uma árvore de decisão usando um novo conjunto de treino gerado com a função train_test_split. Utilize 20% de dados de teste e, desta vez, não **especifique valor nenhum para o random_state**.\n",
        "\n",
        "2. Faça a predição para as instâncias especificadas abaixo e preencha na tabela do excel indicada no **Moodle** a classificação encontrada (0 para maligno e 1 para benigno).\n"
      ],
      "metadata": {
        "id": "OrsF5WMepURZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_interesting = X[[40, 86, 297, 135, 73], :]\n",
        "y_interesting = y[[40, 86, 297, 135, 73]]\n",
        "\n",
        "\n",
        "# 1. Instancie uma nova árvore de decisão, dessa vez sem especificar o valor de random_state\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# 2. Separe o conjunto em treino e teste, dessa vez sem especificar o valor de random_state\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# 3. Treine a nova árvore usando o conjunto de treino\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# 4. Use a nova árvore treinada para obter predições para os valores de X_interesting acima.\n",
        "y_pred = dt.predict(X_interesting)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "hDqpSxNQqBHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## O Efeito da Poda"
      ],
      "metadata": {
        "id": "AZelTK5blG_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As árvores de decisão treinadas nos itens anteriores não possuíam nenhuma forma de poda. No entanto, é possível utilizar técnicas de poda através do scikit-learn. Como consequência, elas podem ter uma complexidade além do que é necessário na modelagem do problema.\n",
        "\n"
      ],
      "metadata": {
        "id": "IYchPiY3lPMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo de Pré-poda: profundidade máxima da árvore\n",
        "Podemos especificar a profundidade máxima da árvore utilizando o parâmetro max_depth."
      ],
      "metadata": {
        "id": "rKvCQYSjovEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(max_depth=2)\n",
        "dt.fit(X, y)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "_ = plot_tree(dt, feature_names=feature_names, class_names=target_names)"
      ],
      "metadata": {
        "id": "WrgD6yAupHUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo gera árvores de decisão com diferentes profundidades máximas e as avalia em termos de acurácia.\n",
        "\n",
        "Observe que todas as árvores são treinadas e avaliadas com os mesmos conjuntos de treino e teste, visto que especificamos o parâmetro $random\\_state = 0$.\n",
        "\n",
        "Com base nesse código, e possíveis modificações que você faça a ele, responda à **Questão  4** do questionário.\n",
        "\n",
        "**Não mude o valor que está sendo passado em random_state=0**.\n"
      ],
      "metadata": {
        "id": "5bzmcFPutJR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "max_depths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, None]  # None faz com que essa poda não seja aplicada\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "for depth in max_depths:\n",
        "  dt = DecisionTreeClassifier(max_depth=depth, random_state=0)\n",
        "  dt.fit(X_train, y_train)\n",
        "\n",
        "  te_y_pred = dt.predict(X_test)\n",
        "  tr_y_pred = dt.predict(X_train)\n",
        "\n",
        "  tr_acc = accuracy_score(y_train, tr_y_pred)\n",
        "  te_acc = accuracy_score(y_test, te_y_pred)\n",
        "  train_acc.append(tr_acc)\n",
        "  test_acc.append(te_acc)\n",
        "\n",
        "pd.DataFrame(data={\"Train Acc\": train_acc, \"Test Acc\": test_acc}, index= [f\"mx_depth = {i}\" for i in max_depths])"
      ],
      "metadata": {
        "id": "qfZo89aUuWVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo de Pós-poda: Custo-complexidade\n",
        "\n",
        "A biblioteca scikit-learn possui uma implementação de pós-poda por custo-complexidade, baseada no parâmetro de custo-complexidade $\\alpha \\ge 0$.\n",
        "\n",
        "Na implementação descrita na biblioteca, é definido também um custo-complexidade efetivo do nodo. Quanto maior for a taxa de erros ao se podar a subárvore de um nodo, maior será seu custo-complexidade efetivo. Além disso, quanto maior for a complexidade (número de nodos terminais) da subárvore do nodo, menor será seu custo-complexidade efetivo.\n",
        "Em resumo, um nodo com alto custo-complexidade efetivo é um nodo importante para diminuir a taxa de erros e com baixa complexidade.\n",
        "\n",
        "Dentro da biblioteca, passamos um parâmetro $ccp\\_alpha$ que serve como um custo-complexidade efetivo de corte: subárvores são podadas enquanto houver nodos com custo-complexidade menor do que o parâmetro $ccp\\_alpha$.\n",
        "Ou seja, quando maior for o parâmetro, mais intensa será a poda.\n",
        "\n",
        "Para mais informações:\n",
        "* https://scikit-learn.org/stable/modules/tree.html#minimal-cost-complexity-pruning\n",
        "* https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html\n",
        "\n",
        "Use o código abaixo para resolver à **Questão 5**."
      ],
      "metadata": {
        "id": "3IHz5Y-KvrCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_acc_vs_ccp(accuracies_train, accuracies_test, ccps):\n",
        "  fig, ax = plt.subplots(figsize=(8, 4))\n",
        "  ax.set_xlabel(\"alpha\")\n",
        "  ax.set_ylabel(\"accuracy\")\n",
        "  ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "  ax.plot(ccps, accuracies_train, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
        "  ax.plot(ccps, accuracies_test, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
        "  ax.legend()\n",
        "  ax.grid()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "accs_train = []\n",
        "accs_test = []\n",
        "ccps = [k * 0.001 for k in range(0, 50, 2)]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "for ccp in ccps:\n",
        "  dt = DecisionTreeClassifier(ccp_alpha=ccp, random_state=0)\n",
        "  dt.fit(X_train, y_train)\n",
        "\n",
        "  y_pred_train = dt.predict(X_train)\n",
        "  acc_train = accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "  y_pred_test = dt.predict(X_test)\n",
        "  acc_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "  accs_train.append(acc_train)\n",
        "  accs_test.append(acc_test)\n",
        "\n",
        "plot_acc_vs_ccp(accs_train, accs_test, ccps)"
      ],
      "metadata": {
        "id": "vHVEBHEG3Ugd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depths = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, None] # None faz com que essa poda não seja aplicada\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "acc_train = []\n",
        "acc_test = []\n",
        "\n",
        "for depth in max_depths:\n",
        "    dt = DecisionTreeClassifier(max_depth=depth, random_state=0)\n",
        "    dt.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = dt.predict(X_test)\n",
        "    acc_test.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "    y_pred2 = dt.predict(X_train)\n",
        "    acc_train.append(accuracy_score(y_train, y_pred2))\n",
        "\n",
        "print(acc_train)\n",
        "print(acc_test)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "ax.set_xlabel(\"max depth\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs max depth for training and testing sets\")\n",
        "ax.plot(max_depths, acc_train, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
        "ax.plot(max_depths, acc_test, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
        "ax.legend()\n",
        "ax.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k39_shwqnUXs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}