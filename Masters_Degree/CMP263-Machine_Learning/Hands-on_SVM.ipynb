{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FA12O8Tpjmk"
      },
      "source": [
        "# CMP263 - Aprendizagem de Máquina - INF/UFRGS\n",
        "\n",
        "## Atividade Prática: Máquinas de Vetores de Suporte\n",
        "\n",
        "---\n",
        "***Observação:*** *Este notebook é disponibilizado aos alunos como complemento às aulas síncronas e aos slides preparados pela professora. Desta forma, os principais conceitos são apresentados no material teórico fornecido. O objetivo deste notebook é reforçar os conceitos e demonstrar questões práticas no uso de diferentes algoritmos e estratégias de Aprendizado de Máquina.*\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgsiZ2JI29zu"
      },
      "source": [
        "<br>\n",
        "\n",
        "## **Aula 04** - **Tópico: Máquinas de Vetores de Suporte**\n",
        "\n",
        "<br>\n",
        "\n",
        "O algoritmo **Máquinas de Vetores de Suporte**, conhecido por **SVM** (de *Support Vector Machines*, em inglês), é amplamente utilizado para tarefas de classificação e regressão, possuindo uma grande versatilidade e alto poder de modelagem para problemas lineares e não-lineares.\n",
        "\n",
        "Conforme discutido em aula, o algoritmo encontra a fronteira de decisão formulando a tarefa de aprendizado como um problema de otimização. O SVM localiza a reta ou hiperplano que separa as instâncias de treinamento em duas regiões de forma a maximizar a margem entre os vetores de suporte das duas classes analisadas. Para problemas multiclasse, a tarefa de classificação é decomposta em um conjunto de problemas de classificação binária.\n",
        "\n",
        "A versatilidade do SVM vem do uso de diferentes tipos de kernel, que são funções que realizam transformações nos dados a fim de projetá-los em um espaço de dimensão superior, de forma a permitir que relações não-lineares sejam modeladas com um classificador linear. Além do kernel linear, outros tipos de kernel muito utilizados são o Polinomial e o Radial Basis Function (RBF).\n",
        "\n",
        "<br>\n",
        "\n",
        "**Objetivo deste notebook**: Exercitar o uso de SVM em tarefas de classificação, comparando diferentes tipos de kernel e realizando a otimização de hiperparâmetros do algoritmo.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbJNQfaM4ERT"
      },
      "source": [
        "##**Determinando a qualidade de vinhos verdes Portugueses**\n",
        "\n",
        "*Seria possível prever as preferências humanas sobre vinhos verdes (principalmente de provadores profissionais) a partir de testes analíticos que quantificam propriedades químicas dos vinhos?*\n",
        "\n",
        "Nesta atividade, vamos analisar um conjunto de observações sobre diversas amostras de vinho verde Português (do tipo branco), envolvendo suas propriedades químicas e classificação realizada por provadores através de análise sensorial.\n",
        "\n",
        "O preço do vinho depende de um conceito bastante abstrato de apreciação do vinho a partir de análise sensorial pelos provadores, cuja opinião pode ter um alto grau de variabilidade. Outro fator chave na certificação e avaliação da qualidade do vinho são os testes análiticos realizados em laboratório e facilmente disponíveis na etapa de certificação. Estes testes levam em consideração fatores como acidez, nível de pH, presença de açúcar e outras propriedades químicas. Para o setor vitivinícola, seria de interesse que a análise de qualidade humana no processo de degustação pudesse estar relacionada com as propriedades químicas do vinho aferidas com os testes analíticos. Assim,  o processo de avaliação e certificação da garantia da qualidade do vinho poderia ser mais controlado.\n",
        "\n",
        "\n",
        "O conjunto de dados a ser analisado nesta atividade possui informações para 4898 amostras de vinhos verdes (tipo branco), todas produzidos em uma determinada zona de Portugal. Os atributos são coletados para 12 propriedades diferentes dos vinho: uma das quais é Qualidade, com base em análise sensorial por provadores, e as restantes são propriedades químicas dos vinhos, incluindo densidade, acidez, teor alcoólico, etc. Todas as propriedades químicas dos vinhos são variáveis ​​contínuas. A qualidade é uma variável ordinal com uma classificação possível de 1 (pior) a 10 (melhor). Cada variedade de vinho é provada por três provadores independentes e a classificação final atribuída é a classificação mediana dada pelos provadores.\n",
        "\n",
        "O conjunto de dados original foi publicado no artigo: *Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. (2009). Modeling wine preferences by data mining from physicochemical properties. Decision support systems, 47(4), 547-553.*\n",
        "\n",
        "O objetivo desta tarefa é abordar a questão apontada no início desta seção, desenvolvendo um modelo capaz de predizer a classificação de um vinho com base nas suas propriedades químicas avaliadas em testes analíticos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiutqCcGYYM0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbr-VwMq6OPG"
      },
      "source": [
        "###Carregando e inspecionando os dados\n",
        "\n",
        "Primeiramente, vamos carregar algumas bibliotecas importantes do Python e os dados a serem utilizados neste estudo. Os dados são disponibilizados através de um link, que também pode ser diretamente acessado pelos alunos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lyNg5Sluhbg"
      },
      "outputs": [],
      "source": [
        "## Carregando as bibliotecas necessárias\n",
        "%matplotlib inline\n",
        "import pandas as pd             # para análise de dados\n",
        "import matplotlib.pyplot as plt # para visualização de informações\n",
        "import seaborn as sns           # para visualização de informações\n",
        "import numpy as np              # para operações com arrays multidimensionais\n",
        "from sklearn.svm import SVC  ## para treinar um SVM\n",
        "from sklearn.model_selection import train_test_split # para divisão de dados\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score,accuracy_score,ConfusionMatrixDisplay ## para avaliação dos modelos\n",
        "sns.set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPcnFsAB9kv0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_table(\"https://drive.google.com/uc?export=view&id=11YsVJck74_gyADzGJSU9Uwn8cDq_l3BD\",sep=\";\")\n",
        "df.head()  # para visualizar apenas as 5 primeiras linhas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCBVXyya-_tM"
      },
      "outputs": [],
      "source": [
        "## Características gerais do dataset\n",
        "print(\"O conjunto de dados possui {} linhas e {} colunas\".format(df.shape[0], df.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqoChZTpAEMu"
      },
      "source": [
        "A coluna *'quality'* contém a classificação de qualidade de cada vinho, aferida pelos provadores. Vamos avaliar como as instâncias estão distribuídas entre os diferentes valores de *'quality'* presentes no dataset (originalmente os mesmos podem variar entre 0 e 10)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0NT9TCiAeLX"
      },
      "outputs": [],
      "source": [
        "## Distribuição do atributo alvo, 'quality'\n",
        "sns.countplot(x='quality', data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMupLQ6yOGGa"
      },
      "outputs": [],
      "source": [
        "## Imprimindo o valor exato de número de instâncias por nota\n",
        "print(df.groupby('quality').size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFZtoZCjOBCs"
      },
      "source": [
        "Podemos perceber que todos os vinhos no conjunto de dados estão classificados com notas entre 3 e 9. Entretanto, poucos vinhos estão classificados nos extremos da distribuição (notas 3 e 9)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FfabKeQT8ja"
      },
      "source": [
        "Também é importante sempre confirmarmos os tipos de dados de cada atributo, bem como se existem valores faltantes. A célula seguinte faz esta inspeção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA30OBnnqPXf"
      },
      "outputs": [],
      "source": [
        "df.info()\n",
        "\n",
        "## Para analisar valores faltantes, quando codificados como NaN, podemos usar o\n",
        "## comando abaixo\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57_WB7PqW5_A"
      },
      "source": [
        "Vamos analisar a distribuição de valores para os atributos, os quais são todos numéricos como foi possível confirmar na célula de código anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2VyTmPuxkWB"
      },
      "outputs": [],
      "source": [
        "## Criando vetor com nome dos atributos\n",
        "features_names = df.columns.drop(['quality'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QEWJ4FdEtxa"
      },
      "outputs": [],
      "source": [
        "## Gerar um gráfico para cada variável numérica com a distribuição\n",
        "## de frequência. Avaliar a distribuição geral ou, opcionalmente,\n",
        "## a distribuição por classe (classificação do vinho)\n",
        "\n",
        "## Distribuição geral\n",
        "def dist_plot(df,columns):\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    for indx, var  in enumerate(columns):\n",
        "        plt.subplot(4, 3, indx+1)\n",
        "        g = sns.histplot(x=var, data=df)\n",
        "    plt.tight_layout()\n",
        "\n",
        "## Distribuição por classe\n",
        "def dist_plot_perclass(df,columns,label):\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    for indx, var  in enumerate(columns):\n",
        "        plt.subplot(4, 3, indx+1)\n",
        "        sns.color_palette(\"pastel\")\n",
        "        g = sns.histplot(x=var, data=df, hue=label,palette='muted')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "dist_plot(df, features_names)\n",
        "#dist_plot_perclass(df, features_names, 'quality')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXoMj3hpDvil"
      },
      "source": [
        "**Pergunta >>>** Neste ponto já é possível avaliar a necessidade de normalização dos dados para treinamento do SVM. Analise o quanto os dados demandam pré-processamento para normalização dos valores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBiPT880TLY6"
      },
      "source": [
        "> ***Sua resposta aqui:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVoH2AFdErcu"
      },
      "source": [
        "O gráfico abaixo mostra de outra forma como variam os valores dos atributos, considerando todas as instâncias no conjunto de dados.\n",
        "\n",
        "**Pergunta >>>** Quais atributos possuem as escalas de valores mais discrepantes em relação ao conjunto total de atributos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUq8N5ZCBmJ-"
      },
      "source": [
        "> ***Sua resposta aqui:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqndUq5OP_QX"
      },
      "outputs": [],
      "source": [
        "df.drop(['quality'],axis=1).plot(figsize=(15,7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_gTnhwoFKrs"
      },
      "source": [
        "Por fim, para auxiliar no entendimento do problema, é interessante avaliar a correlação entre atributos, bem como a correlação dos atributos com a classificação da qualidade do vinho. Vamos criar um heatmap com a correlação de Pearson entre os atributos da base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWwSliZoPNtC"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(df.corr(), annot=True, cmap = 'coolwarm')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899ouo7iGX0f"
      },
      "source": [
        "É possível visualizar o comportamente da correlação entre atributos e a classe através de lineplots. Visualize os dados para alguns atributos selecionados que apresentem correlação positiva ou negativa com quality (mesmo que a correlação seja fraca). Digite o nome do atributo no campo abaixo (feature_sel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8ukjJrBF6KK"
      },
      "outputs": [],
      "source": [
        "feature_sel = \"density\" #@param {type:\"string\"}\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.lineplot(data=df, x=\"quality\",y=feature_sel,color='r')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHD3JpfDQ7Zj"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "### Estruturando a tarefa de classificação: vinho bom ou medíocre?\n",
        "\n",
        "A análise exploratória dos dados nos mostrou que a qualidade dos vinhos no conjunto de dados disponível varia entre 3 e 9, com poucas instâncias sendo classificadas com as notas extremas. A distribuição dos dados sugere que a grande maioria dos vinhos possuem notas 5, 6 e 7. A falta de representatividade de vinhos com as demais classificações pode se apresentar como um problema para o desenvolvimento do modelo.\n",
        "\n",
        "**Pergunta >>>** Qual possivelmente será o desempenho de um modelo treinado com estes dados para a classificação de novos vinhos com nota 9-10 ou nota 0-2?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlj9nNE6BoWo"
      },
      "source": [
        "> ***Sua resposta aqui:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEsVyfIcBp44"
      },
      "source": [
        "Para dar continuidade à modelagem do problema de classificação dos vinhos, vamos **investigar a possibilidade de distinguir bons vinhos de vinhos medíocres ou ruins**, utilizando **a nota de 7** como um ponto de corte. Vinhos com nota 7 ou superior serão classificados como bons vinhos (1), enquanto vinhos com notas 0-6 serão classificados como medíocres (0).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJ5ejYnGTUsR"
      },
      "outputs": [],
      "source": [
        "df['quality'] = df['quality'].replace([3, 4, 5, 6], 0)\n",
        "df['quality'] = df['quality'].replace([7, 8, 9], 1)\n",
        "sns.countplot(x='quality', data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63nQ-E0jVQzW"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Criando conjuntos de treino, validação e teste\n",
        "\n",
        "Faremos a divisão dos dados em treino, validação e teste na proporção (sugerida) de 70%/15%/15% para fazer avaliação de desempenho dos modelos com um *holdout de 3 vias*. Na célula de código abaixo, os dados são inicialmente divididos entre duas variáveis: uma variável contendo os atributos e outra a classe a ser predita. Na sequência, são implementados os seguintes passos:\n",
        "\n",
        "\n",
        "1.   Utilizada a função train_test_split() para dividir os dados em treino, validação e teste.\n",
        "2.   Normalização  dos dados usando o método MaxMin. Lembre-se que primeiramente os parâmetros de normalização são estimados a partir dos dados de treino e então aplicados a todos os três conjuntos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABN2LAyMYIRb"
      },
      "outputs": [],
      "source": [
        "## Separa o dataset em duas variáveis: os atributos/entradas (X) e a classe/saída (y)\n",
        "X = df.drop(['quality'], axis=1)\n",
        "y = df['quality'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQM_D8QzYRiE"
      },
      "outputs": [],
      "source": [
        "## Definindo as proporções de treino, validação e teste.\n",
        "train_ratio = 0.70\n",
        "test_ratio = 0.15\n",
        "validation_ratio = 0.15\n",
        "\n",
        "## Fazendo a primeira divisão, para separar um conjunto de teste dos demais.\n",
        "## Assuma X_train e y_train para os dados de treinamento e X_test e y_test para os de teste\n",
        "## Dica: configure o random_state para facilitar reprodutibilidade dos experimentos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio,stratify=y,random_state=42)\n",
        "\n",
        "## Fazendo a segunda divisão, para gerar o conjunto de treino e validação a partir\n",
        "## do conjunto de 'treinamento' da divisão anterior\n",
        "## Assuma X_train e y_train para os dados de treinamento e X_valid e y_valid para os de teste\n",
        "## Dica: configure o random_state para facilitar reprodutibilidade dos experimentos\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=validation_ratio/(train_ratio+test_ratio),stratify=y_train,random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5hC8OHiZCAt"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "## O MinMaxScaler transformará os dados para que fiquem no intervalo [0,1]\n",
        "scaler = MinMaxScaler() #StandardScaler()\n",
        "\n",
        "## Iniciar a normalização dos dados. Primeiro fazer um 'fit' do scaler nos\n",
        "## dados de treino. Esta etapa visa \"aprender\" os parâmetros para normalização.\n",
        "## No caso do MinMaxScales, são os valores mínimos e máximos de cada atributo\n",
        "scaler.fit(X_train)\n",
        "\n",
        "## Aplicar a normalização nos três conjuntos de dados:\n",
        "X_train = scaler.transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyAocGK-dNoF"
      },
      "source": [
        "Com os dados normalizados, podemos melhor inspecionar a distribuição de valores por classe, considerando o problema de classificação binário. Vamos fazer a análise para o conjunto de treino, observando as medianas para cada classe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yufMahVxeCM_"
      },
      "outputs": [],
      "source": [
        "df_train_norm =  pd.DataFrame(X_train,columns=features_names)\n",
        "df_ytrain =  pd.DataFrame(y_train,columns=['quality'],dtype=int)\n",
        "df_train_norm =  pd.concat([df_train_norm,df_ytrain], axis=1)\n",
        "ave_values = df_train_norm.groupby(\"quality\").median()\n",
        "ave_values.plot(kind=\"bar\",figsize=(15,7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuhzlay5bmQB"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "### Treinamento de modelos SVM com Kernel Linear\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0FaUD8G7jRN"
      },
      "source": [
        "Como vimos em aula, o modelo SVM com Kernel Linear é o \"mais simples\" dentre os modelos de SVM. Ele possui o hiperparâmetro C (termo de regularização), comum a todos os modelos de SVM, e que precisa ser otimizado para cada problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2an5tngpV4R"
      },
      "source": [
        "#### Otimização \"manual\" do hiperparâmetro C\n",
        "No código abaixo, vamos fazer a otimização do hiperparâmetro C através da implementação de um loop. Para cada modelo, vamos avaliar a acurácia, recall e precisão. Vamos assumir que o melhor modelo será aquele que maximiza a acurácia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b27Xz3zHqz60"
      },
      "outputs": [],
      "source": [
        "## Definindo um array para armazenar o desempenho de cada modelo treinado e avaliado\n",
        "perf_valid = []\n",
        "\n",
        "## Definindo valores de C a serem testados\n",
        "param_grid_C = [0.1, 1, 5, 10, 50, 100] #valores para C, termo de regularização\n",
        "\n",
        "# Treinando e avaliado os modelos com cada valor de hiperparâmetro especificado\n",
        "for ii in range(len(param_grid_C)):\n",
        "    clf = SVC(kernel='linear',C=param_grid_C[ii],random_state=42, class_weight='balanced') ##class_weight minimiza o efeito de termos mais exemplos para vinhos medíocres/ruins\n",
        "    clf.fit(X_train, y_train)\n",
        "    pred_i = clf.predict(X_valid)\n",
        "    perf_valid.append([param_grid_C[ii],accuracy_score(y_valid, pred_i),recall_score(y_valid, pred_i),precision_score(y_valid, pred_i)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrsT8OJBsglE"
      },
      "outputs": [],
      "source": [
        "perf_df = pd.DataFrame(perf_valid, columns=['C','accuracy','recall','precision'])\n",
        "perf_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHx5_o0d0AbW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "## Transforma o dataframe para facilitar plotar todas as métricas na mesma figura\n",
        "perf_df_melt = pd.melt(perf_df, id_vars=['C'], value_vars=['accuracy','recall','precision'])\n",
        "sns.lineplot(data=perf_df_melt,x='C',y='value',hue='variable',palette='muted',marker='o')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFNNeYOh7fqU"
      },
      "source": [
        "**Pergunta >>>** Qual valor de C maximiza a acurácia? Como são os valores de acurácia, recall e precisão para este modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs5MNIOjCF5m"
      },
      "source": [
        "> ***Sua resposta aqui:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqIFtWSroFMb"
      },
      "source": [
        "**Pergunta >>>** Qual o impacto de usar a opção `class_weight='balanced'` no código? Tente executar sem esta opção e observe o efeito nos resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFEUyyvKCIOi"
      },
      "source": [
        "> ***Sua resposta aqui:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmT8qRSW8MrA"
      },
      "source": [
        "#### Otimização do hiperparâmetro C com GridSearchCV\n",
        "\n",
        "O scikit-learn disponibiliza o método GridSearchCV, que permite fazer a otimização de hiperparâmetros de forma mais automática. É especialmente útil quando queremos testar c**ombinações** de valores para diferentes hiperparâmetros. O código abaixo aplica o GridSearchCV usando as divisões de dados de treino e validação pré-definidas (através do método PredefinedSplit). Portanto, devemos chegar ao mesmo resultado da análise anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLtKvrUwhQ3p"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import PredefinedSplit, GridSearchCV ## para auxiliar na otimização de hiperparâmetros\n",
        "\n",
        "# Cria lista com os dados de treinamento com índice -1 e dados de validação com índice 0\n",
        "# Concatena os dados de treino e validação com as partições pré-definidas\n",
        "split_index = [-1]*len(X_train) + [0]*len(X_valid)\n",
        "X_gridSearch = np.concatenate((X_train, X_valid), axis=0)\n",
        "y_gridSearch = np.concatenate((y_train, y_valid), axis=0)\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "## Define métricas de desempenho a serem estimadas\n",
        "scoring = {'Accuracy':'accuracy', 'Precision': 'precision', 'Recall':'recall'}\n",
        "\n",
        "## Define o algoritmo base da otimização de hiperparâmetros\n",
        "estimator = SVC(kernel='linear',class_weight='balanced')\n",
        "\n",
        "## Define a grid de hiperparâmetros a serem testados\n",
        "param_grid = {'C': [0.1, 1, 5, 10, 50]}\n",
        "#param_grid = {'C': [0.1, 1, 5, 10, 50, 100]}#, 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
        "#param_grid = {'C': [0.1, 1, 5, 10, 50, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
        "\n",
        "\n",
        "## Aplica GridSearch com as partições de treino/validação pré-definidas\n",
        "gridS = GridSearchCV(estimator = estimator,\n",
        "                   cv=pds,\n",
        "                   param_grid=param_grid,\n",
        "                   scoring=scoring,\n",
        "                   refit='Accuracy', ##métrica a ser utilizada para definir o melhor modelo, retreinando-o com toda a base\n",
        "                   return_train_score=True)\n",
        "gridS.fit(X_gridSearch, y_gridSearch)\n",
        "print('Desempenho máximo obtido com: {}'.format(gridS.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7mXcZ0e_IIH"
      },
      "outputs": [],
      "source": [
        "print(gridS.cv_results_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGqCgcp0nUpr"
      },
      "source": [
        "A visualização dos dados pode nos auxiliar a explorar o resultado da otimização de hiperparâmetros. O código abaixo criar um gráfico a partir dos resultados do GridSearchSV, focando na variação de um hiperparâmetro. Neste caso, analisamos C, o único hiperparâmetro variado na análise. (*OBS.: Não se preocupe se não entender todos os detalhes de implementação da função, ela é apenas um utilitário na visualização de dados*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5g7w2L9b6Ml0"
      },
      "outputs": [],
      "source": [
        "## O código desta célula cria um gráfico de variação de desempenho de acordo com\n",
        "## o valor do hiperparâmetro C.\n",
        "\n",
        "results = gridS.cv_results_\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title(\"Resultados do GridSearchCV\",\n",
        "      fontsize=16)\n",
        "\n",
        "plt.xlabel(\"Hyperparameter\") ##nome do parâmetro a ser analisado\n",
        "plt.ylabel(\"Performance\")\n",
        "\n",
        "ax = plt.gca()\n",
        "\n",
        "## Criar um numpy array para os resultados do hiperparâmetro a ser analisado.\n",
        "## O hiperparâmetro C está identificado no objeto retornado pelo gridSearchCV\n",
        "## como param_C\n",
        "X_axis = np.array(results['param_C'].data, dtype=float)\n",
        "\n",
        "for scorer, color in zip(sorted(scoring), ['g', 'k', 'b', 'r']):\n",
        "    for sample, style in (('train', '--'), ('test', '-')):\n",
        "       sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
        "       sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
        "       ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
        "                    sample_score_mean + sample_score_std,\n",
        "                    alpha=0.1 if sample == 'test' else 0, color=color)\n",
        "       ax.plot(X_axis, sample_score_mean, style, color=color,\n",
        "            alpha=1 if sample == 'test' else 0.7,\n",
        "            label=\"%s (%s)\" % (scorer, sample))\n",
        "\n",
        "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
        "    best_score = results['mean_test_%s' % scorer][best_index]\n",
        "\n",
        "    ## Plota uma linha vertical para o valor de hiperparâmetro que maximiza a métrica de desempenho\n",
        "    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
        "        linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
        "    ## Anota o valor do melhor score\n",
        "    ax.annotate(\"%0.3f\" % best_score,\n",
        "            (X_axis[best_index], best_score + 0.008))\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suxo6JBUFXOk"
      },
      "source": [
        "Analisando o desempenho do modelo treinado com o melhor valor de C nos dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDIrXCrSi9ZH"
      },
      "outputs": [],
      "source": [
        "y_pred_svmLinear = gridS.predict(X_test) ##predição usando SVM com a melhor configuração de hiperparâmetros encontrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7CxStgtE4JW"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred_svmLinear,labels=gridS.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gridS.classes_)\n",
        "disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "print('Acurácia: {}'.format(round(accuracy_score(y_test, y_pred_svmLinear),3)))\n",
        "print('Recall: {}'.format(round(recall_score(y_test, y_pred_svmLinear,pos_label=1),3)))\n",
        "print('Precisão: {}'.format(round(precision_score(y_test, y_pred_svmLinear,pos_label=1),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxJy8wbS-k-n"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "### Comparando diferentes funções de Kernel no SVM\n",
        "\n",
        "\n",
        "Nesta seção, vamos comparar diferentes tipos de Kernel em um algoritmo SVM. Utilizaremos o método GridSearchCV do scikit-learn pela praticidade do mesmo. Entretanto, também seria possível realizar a mesma análise com um loop definido por nós, testando diferentes combinações de valores de hiperparâmetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wfQR6I9BfmI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import PredefinedSplit, GridSearchCV ## para auxiliar na otimização de hiperparâmetros\n",
        "\n",
        "\n",
        "## Cria lista com os dados de treinamento com índice -1 e dados de validação com índice 0\n",
        "## Concatena os dados de treino e validação com as partições pré-definidas\n",
        "split_index = [-1]*len(X_train) + [0]*len(X_valid)\n",
        "X_gridSearch = np.concatenate((X_train, X_valid), axis=0)\n",
        "y_gridSearch = np.concatenate((y_train, y_valid), axis=0)\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "# ## Define métricas de desempenho a serem estimadas\n",
        "scoring = {'Accuracy':'accuracy', 'Precision': 'precision', 'Recall':'recall'}\n",
        "\n",
        "## Define o algoritmo base da otimização de hiperparâmetros\n",
        "estimator = SVC(class_weight='balanced')\n",
        "\n",
        "## Define a grid de hiperparâmetros a serem testados\n",
        "param_grid = {'C': [0.1, 1, 5, 10, 50, 100], 'kernel': ['rbf', 'poly', 'sigmoid']}#,'gamma': [1,0.1,0.01,0.001]} ## gamma foi removido para reduzir tempo de execução\n",
        "\n",
        "## Aplica GridSearch com as partições de treino/validação pré-definidas\n",
        "gridS2 = GridSearchCV(estimator = estimator,\n",
        "                   cv=pds,\n",
        "                   param_grid=param_grid,\n",
        "                   scoring=scoring,\n",
        "                   refit='Accuracy', ##métrica a ser utilizada para definir o melhor modelo, retreinando-o com toda a base\n",
        "                   return_train_score=True)\n",
        "gridS2.fit(X_gridSearch, y_gridSearch)\n",
        "print('Desempenho máximo obtido com: {}'.format(gridS2.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joNArdzPB4qr"
      },
      "outputs": [],
      "source": [
        "results = gridS2.cv_results_\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.title(\"Resultados do GridSearchCV\",\n",
        "      fontsize=16)\n",
        "\n",
        "plt.xlabel(\"Hyperparameter\") ##nome do parâmetro a ser analisado\n",
        "plt.ylabel(\"Performance\")\n",
        "\n",
        "ax = plt.gca()\n",
        "\n",
        "## Criar um numpy array para os resultados do hiperparâmetro a ser analisado\n",
        "X_axis = np.array(results['param_kernel'].data)#, dtype=float)\n",
        "\n",
        "for scorer, color in zip(sorted(scoring), ['g', 'k', 'b', 'r']):\n",
        "    for sample, style in (('train', '--'), ('test', '-')):\n",
        "       sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
        "       sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
        "       ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
        "                    sample_score_mean + sample_score_std,\n",
        "                    alpha=0.1 if sample == 'test' else 0, color=color)\n",
        "       ax.plot(X_axis, sample_score_mean, style, color=color,\n",
        "            alpha=1 if sample == 'test' else 0.7,\n",
        "            label=\"%s (%s)\" % (scorer, sample))\n",
        "\n",
        "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
        "    best_score = results['mean_test_%s' % scorer][best_index]\n",
        "\n",
        "    ## Plota uma linha vertical para o valor de hiperparâmetro que maximiza a métrica de desempenho\n",
        "    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
        "        linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
        "    ## Anota o valor do melhor score\n",
        "    ax.annotate(\"%0.3f\" % best_score,\n",
        "            (X_axis[best_index], best_score + 0.008))\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
