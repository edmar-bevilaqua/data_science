{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Programa de Pós-Graduação em Computação - INF/UFRGS**\n",
        "### Disciplina CMP263 - Aprendizagem de Máquina\n",
        "#### *Profa. Mariana Recamonde-Mendoza (mrmendoza@inf.ufrgs.br)*\n",
        "<br>\n",
        "\n",
        "---\n",
        "***Observação:*** *Este notebook é disponibilizado aos alunos como complemento às aulas  e aos slides preparados pela professora. Desta forma, os principais conceitos são apresentados no material teórico fornecido. O objetivo deste notebook é reforçar os conceitos e demonstrar questões práticas no uso de algoritmos e estratégias de avaliação em Aprendizado de Máquina.*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "##**Tópico: Introdução à avaliação de modelos com Holdout**\n",
        "\n",
        "\n",
        "**Objetivos da atividade:**\n",
        "-  Entender o funcionamento da técnica de holdout para avaliação de modelos.\n",
        "- Comparar o desempenho de dois algoritmos, Naive Bayes e KNN, em uma tarefa de classificação.\n",
        "- Aplicar métricas de avaliação como acurácia, precisão, recall, observando a matriz de confusão.\n",
        "- Implementar uma estratégia básica para seleção de hiperparâmetros para o KNN, interpretando os resultados.\n",
        "- Analisar o impacto de aspectos como dimensão dos dados, aleatoriedade na divisão de dados e repetições na avaliação de modelos com Holdout."
      ],
      "metadata": {
        "id": "DDELdQ-j0lDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Carregando as bibliotecas e dados\n"
      ],
      "metadata": {
        "id": "bgiI6FV00zre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd             # biblioteca para análise de dados\n",
        "import matplotlib.pyplot as plt # biblioteca para visualização de informações\n",
        "import seaborn as sns           # biblioteca para visualização de informações\n",
        "import numpy as np              # biblioteca para operações com arrays multidimensionais\n",
        "from sklearn.datasets import load_breast_cancer ## conjunto de dados a ser analisado\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "9wR4Z8hcrMC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Carregando os dados - Câncer de Mama\n",
        "## https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\n",
        "\n",
        "data = load_breast_cancer() ## carrega os dados de breast cancer\n",
        "X = data.data  # matriz contendo os atributos\n",
        "y = data.target  # vetor contendo a classe (0 para maligno e 1 para benigno) de cada instância\n",
        "feature_names = data.feature_names  # nome de cada atributo\n",
        "target_names = data.target_names  # nome de cada classe"
      ],
      "metadata": {
        "id": "Wy4AyLeusoAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dimensões de X: {X.shape}\\n\")\n",
        "print(f\"Dimensões de y: {y.shape}\\n\")\n",
        "print(f\"Nomes dos atributos: {feature_names}\\n\")\n",
        "print(f\"Nomes das classes: {target_names}\")"
      ],
      "metadata": {
        "id": "DVvGJ90UC5bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## transforma NumPy Array para Pandas DataFrame\n",
        "data_df = pd.DataFrame(X,columns=feature_names)\n",
        "\n",
        "## sumariza os atributos numéricos (todos, neste caso)\n",
        "data_df.describe()"
      ],
      "metadata": {
        "id": "QlV9xcg4ssZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fazendo a divisão dos dados com Holdout de 3 vias (treino/validação/teste)"
      ],
      "metadata": {
        "id": "6xLyeKJl1Clw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Carregando funções específicas do scikit-learn\n",
        "\n",
        "from sklearn.model_selection import train_test_split # função do scikit-learn que implementa um holdout\n",
        "from sklearn.naive_bayes import GaussianNB # Naive Bayes Gaussiano\n",
        "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report # métricas de desempenho\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # matriz de confusão"
      ],
      "metadata": {
        "id": "xxkLz8Oh5QN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Exemplo de HOLDOUT de 2 vias: separa os dados em treino e teste, de forma estratificada (não utilizado aqui)\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y) ## atenção: inicialmente, não mude o random_state para este exercício"
      ],
      "metadata": {
        "id": "lAb7KWsuDBnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## HOLDOUT de 3 vias: separa os dados em treino e teste, de forma estratificada\n",
        "\n",
        "## Definindo as proporções de treino, validação e teste.\n",
        "train_ratio = 0.70\n",
        "test_ratio = 0.15\n",
        "validation_ratio = 0.15\n",
        "\n",
        "## Fazendo a primeira divisão, para separar um conjunto de teste dos demais.\n",
        "## Assuma X_temp e y_temp para os dados de treinamento+validação e X_test e y_test para os de teste\n",
        "## Dica: configure o random_state para facilitar reprodutibilidade dos experimentos\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_ratio,random_state=42,stratify=y)\n",
        "\n",
        "## Fazendo a segunda divisão, para gerar o conjunto de treino e validação a partir\n",
        "## do conjunto de 'treinamento' da divisão anterior\n",
        "## Assuma X_train e y_train para os dados de treinamento e X_valid e y_valid para os de teste\n",
        "## Dica: configure o random_state para facilitar reprodutibilidade dos experimentos\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=validation_ratio/(train_ratio+test_ratio),random_state=42,stratify=y_temp)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_valid.shape)"
      ],
      "metadata": {
        "id": "8-vT9obntkvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**>> Analise e Discuta:**\n",
        "\n",
        "\n",
        "\n",
        "1. Considere um cenário com 5 instâncias no conjunto de treinamento e  95 instâncias no conjunto de teste. O quão boa você acha que é a capacidade de generalização do modelo que provavelmente treinaremos?\n",
        "    *   R: Baixa, mesmo que as 5 amostras sejam bem representativas da população, pois o modelo estará se baseando em em pouquíssimos dados para generalizar para muitos dados.\n",
        "\n",
        "2. Sua resposta para 1 muda se tivermos 500 instâncias de treinamento e 9500 instâncias de teste?\n",
        "    *   R: Sim, pois com 500 amostras bem representativas, o modelo tende a errar menos na generalização.\n",
        "\n",
        "3.  Considere um cenário com 95 instâncias no conjunto de treinamento e 5 instâncias no conjunto de teste. O valor de desempenho do teste ainda é uma boa estimativa do poder de generalização?\n",
        "    *   R: Talvez não seja o cenário ideal, porém com 95 instâncias de treino e 5 de teste, o modelo já consegue uma boa estimativa da sua capacidade de generalização, podendo porém, ficar com deficiência de exemplos extremos.\n",
        "\n",
        "4. Sua resposta para 3 muda se tivermos 9500 instâncias de treinamento e 500 instâncias de teste?\n",
        "    *   R: Sim, com 9500 amostras para treino e 500 para teste, é bem possível que nosso conjunto de dados englobe os mais diversos cenários, aumentando a capacidade de generalização do nosso modelo.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "k5s1sT06Hga5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pré-processamento: Normalizando os dados\n",
        "\n",
        "A normalização é feita de forma a evitar **Data Leakage** (vazamento de informações dos dados de teste durante o treinamento dos modelos). Os parâmetros para normalização são estimados a partir dos dados de treino, e posteriormente aplicados para normalizar todos os dados, isto é, treino, validação e teste.\n",
        "\n",
        "A normalização é imprescindível para algoritmos baseados em distâncias, como o kNN."
      ],
      "metadata": {
        "id": "JZITv0JD1JMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler # função do scikit-learn que implementa normalização min-max\n",
        "\n",
        "## O MinMaxScaler transformará os dados para que fiquem no intervalo [0,1] - importante para o kNN\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "## Iniciar a normalização dos dados. Primeiro fazer um 'fit' do scaler nos\n",
        "## dados de treino. Esta etapa visa \"aprender\" os parâmetros para normalização.\n",
        "## No caso do MinMaxScales, são os valores mínimos e máximos de cada atributo\n",
        "scaler.fit(X_train)\n",
        "\n",
        "## Aplicar a normalização nos três conjuntos de dados:\n",
        "X_train = scaler.transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "d4qgslS8tb8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Treinando um modelo Naïve Bayes Gaussiano (para dados numéricos)"
      ],
      "metadata": {
        "id": "C0-JmFSH1X4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar Naive Bayes\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Classificar dados no conjunto de teste\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "\n",
        "# Avaliar o desempenho\n",
        "print(\"Naive Bayes - Desempenho no Conjunto de Teste\")\n",
        "print(f\"Acurácia: {accuracy_score(y_test, y_pred_nb):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_nb):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_nb):.2f}\")\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred_nb))"
      ],
      "metadata": {
        "id": "rRN_8JNZxaH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred_nb,labels=nb_model.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=nb_model.classes_)\n",
        "disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yy60PG2iyYBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Treinando um modelo kNN - com otimização do hiperparâmetro k"
      ],
      "metadata": {
        "id": "OFMHE-Yo1qMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testar KNN com diferentes valores de k\n",
        "# Conjunto de validação é usado para selecionar o melhor k\n",
        "# Conjunto de teste é usado para avaliação final do modelo otimizado\n",
        "\n",
        "# A análise é feita com a distância Euclidiana (padrão)\n",
        "best_k = 1\n",
        "best_score = 0\n",
        "\n",
        "for k in range(1, 17,2):\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_model.fit(X_train, y_train)\n",
        "\n",
        "    # Classificar dados no conjunto de teste\n",
        "    y_pred_valid = knn_model.predict(X_valid)\n",
        "\n",
        "    # Acurácia no conjunto de validação\n",
        "    score = accuracy_score(y_valid, y_pred_valid)\n",
        "    print(f\"K={k}: Acurácia na Validação = {score:.2f}\")\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_k = k\n",
        "\n",
        "print(f\"\\nMelhor valor de K: {best_k} com Acurácia de {best_score:.2f} na Validação\")"
      ],
      "metadata": {
        "id": "UPkhRVSgxv-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação final do KNN com o melhor k\n",
        "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
        "knn_model.fit(X_train, y_train) ## o ideal seria unir treino+validação neste treinamento, mas para fins de comparação entre modelos knn/NB mantive apenas X_train\n",
        "\n",
        "# Classificar dados no conjunto de teste\n",
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "print(f\"\\nKNN - Desempenho com K={best_k} no Conjunto de Teste\")\n",
        "print(f\"Acurácia: {accuracy_score(y_test, y_pred_knn):.2f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_knn):.2f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_knn):.2f}\")\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred_knn))"
      ],
      "metadata": {
        "id": "bev5415AxyQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred_knn,labels=knn_model.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn_model.classes_)\n",
        "disp = disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j__1atJxysZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**>> Analise e Discuta:**\n",
        "\n",
        "Com base nos resultados, qual dos dois modelos apresentou melhor desempenho geral no conjunto de teste, Naïve Bayes ou kNN?\n",
        "Em quais classes o kNN obteve melhor sensibilidade (recall) e precisão do que o Naive Bayes, ou vice versa?\n",
        "\n",
        "---\n",
        "\n",
        "*   R: O modelo KNN com k=5 (acurácia = 0.97) apresentou desempenho superior ao modelo utilizando Naive Bayes Gaussiano (acurácia = 0.94). O valor de recall foi melhor no modelo de KNN com k=5 (recall = 0.98), enquanto que o modelo Naive Bayes ficou com recall = 0.94"
      ],
      "metadata": {
        "id": "T-Usx_6zJA5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Analisando o impacto da divisão aleatória de dados no desempenho dos modelos\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xvQItjrUD8C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar listas para armazenar os resultados\n",
        "accuracies = []\n",
        "random_states = []\n",
        "\n",
        "# Avaliar modelos (naïve Bayes/kNN) 30 vezes, variando o random_state\n",
        "for i in range(30):\n",
        "    random_state = np.random.randint(0, 1000)  # Gerar um random_state aleatório\n",
        "    random_states.append(random_state)\n",
        "\n",
        "    # Dividir os dados entre treino e teste (proporção fixa)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
        "\n",
        "    # Normalizar dados\n",
        "    scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # # Treinar o Naive Bayes\n",
        "    # nb_model = GaussianNB()\n",
        "    # nb_model.fit(X_train, y_train)\n",
        "\n",
        "    # # Classificação e avaliação no conjunto de teste\n",
        "    # y_pred_nb = nb_model.predict(X_test)\n",
        "    # accuracy = accuracy_score(y_test, y_pred_nb)\n",
        "    # accuracies.append(accuracy)\n",
        "\n",
        "    # Treinar o kNN\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "    knn_model.fit(X_train, y_train)\n",
        "\n",
        "    # Classificação e avaliação no conjunto de teste\n",
        "    y_pred_knn = knn_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "    # Exibir o desempenho a cada iteração\n",
        "    print(f\"Iteração {i+1}: Random State={random_state}, Acurácia={accuracy:.2f}\")\n",
        "\n",
        "# Plotar a variação das acurácias\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1, 31), accuracies, marker='o', linestyle='--', color='b')\n",
        "plt.title('Variação da Acurácia do Modelo em 30 Iterações com Random State Diferente')\n",
        "plt.xlabel('Iteração')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.xticks(range(1, 31))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a5auaqizzuHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Amplitude dos resultados\n",
        "max(accuracies) - min(accuracies)"
      ],
      "metadata": {
        "id": "XURprcLG0Gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**>> Analise e Discuta:**\n",
        "\n",
        "Observe a variação do valor de *random_state* na divisão dos dados e os respectivos resultados do desempenho na classificação. Como isso afeta os resultados?  Explique o impacto de diferentes divisões dos dados de treino/validação/teste no desempenho dos modelos. Por que é importante repetir os experimentos várias vezes, variando o random_state? O que a repetição traz em termos de confiabilidade dos resultados?\n",
        "\n",
        "---\n",
        "\n",
        "*   R: O valor de `random_state` determina a \"seed\" que será usada para embaralhar os dados, e este valor é um número aleatório, o que introduz um potencial viés no modelo, visto que a aleatoriedade sem repetição tem como risco inerente a possibilidade de dificultar a boa representatividade da população. Uma boa forma de termos alta representatividade da população é mantermos a aleatoriedade, porém repetidas vezes, fazendo com que a lei dos grandes números entre em ação e com isso nós podemos esperar que a média das amostras se aproxime cada vez mais da média real."
      ],
      "metadata": {
        "id": "RUJqwwZxJ428"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Analisando o impacto do tamanho do conjunto de teste na avaliação de desempenho dos modelos\n",
        "\n"
      ],
      "metadata": {
        "id": "7ZF7RT_jEm_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar listas para armazenar resultados\n",
        "variances = []\n",
        "amplitudes = []\n",
        "avg_accuracies = []\n",
        "\n",
        "# Definir as proporções de conjunto de teste\n",
        "test_sizes = np.arange(0.05, 0.70, 0.05)\n",
        "\n",
        "# Loop para cada proporção de conjunto de teste\n",
        "for test_size in test_sizes:\n",
        "    accuracies = []\n",
        "\n",
        "    # Repetir o experimento 30 vezes para cada tamanho de conjunto de teste\n",
        "    for i in range(30):\n",
        "        random_state = np.random.randint(0, 1000)\n",
        "\n",
        "        # Dividir os dados com a proporção especificada para o conjunto de teste\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "        # Normalizar dados\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # # Treinar o Naive Bayes\n",
        "        # nb_model = GaussianNB()\n",
        "        # nb_model.fit(X_train, y_train)\n",
        "\n",
        "        # # Previsão e avaliação no conjunto de teste\n",
        "        # y_pred_nb = nb_model.predict(X_test)\n",
        "        # accuracy = accuracy_score(y_test, y_pred_nb)\n",
        "        # accuracies.append(accuracy)\n",
        "\n",
        "        # Treinar o kNN\n",
        "        knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "        knn_model.fit(X_train, y_train)\n",
        "\n",
        "        # Previsão e avaliação no conjunto de teste\n",
        "        y_pred_knn = knn_model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    # Calcular variância, amplitude e média dos desempenhos\n",
        "    variance = np.var(accuracies)\n",
        "    amplitude = np.max(accuracies) - np.min(accuracies)\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "\n",
        "    # Armazenar os resultados\n",
        "    variances.append(variance)\n",
        "    amplitudes.append(amplitude)\n",
        "    avg_accuracies.append(avg_accuracy)\n",
        "\n",
        "    # Exibir os resultados intermediários\n",
        "    print(f\"Tamanho do Conjunto de Teste: {test_size*100:.1f}%\")\n",
        "    print(f\"   Média da Acurácia: {avg_accuracy:.3f}\")\n",
        "    print(f\"   Variância: {variance:.5f}\")\n",
        "    print(f\"   Amplitude (Máx - Mín): {amplitude:.3f}\")\n",
        "    print(\"\")\n",
        "\n",
        "# Gráfico: Variação da Acurácia com Diferentes Tamanhos de Conjunto de Teste\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(test_sizes * 100, avg_accuracies, marker='o', linestyle='--', color='b', label=\"Média das Acurácias\")\n",
        "plt.title('Média da Acurácia do KNN com Diferentes Tamanhos de Conjunto de Teste')\n",
        "plt.xlabel('Tamanho do Conjunto de Teste (%)')\n",
        "plt.ylabel('Média da Acurácia')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# # Gráfico: Variância vs Tamanho do Conjunto de Teste\n",
        "# plt.figure(figsize=(10,6))\n",
        "# plt.scatter(test_sizes * 100, variances, color='r', label=\"Variância do Desempenho\")\n",
        "# plt.title('Variância do Desempenho vs Tamanho do Conjunto de Teste')\n",
        "# plt.xlabel('Tamanho do Conjunto de Teste (%)')\n",
        "# plt.ylabel('Variância do Desempenho')\n",
        "# plt.grid(True)\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# Gráfico: Amplitude vs Tamanho do Conjunto de Teste\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(test_sizes * 100, amplitudes, color='g', label=\"Amplitude (Máx - Mín)\")\n",
        "plt.title('Amplitude do Desempenho vs Tamanho do Conjunto de Teste')\n",
        "plt.xlabel('Tamanho do Conjunto de Teste (%)')\n",
        "plt.ylabel('Amplitude do Desempenho')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KBk-_Obc6kZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**>> Analise e Discuta:**\n",
        "\n",
        "Conforme o tamanho do conjunto de teste aumenta, como muda a variância no desempenho do modelo? Por que esse comportamento ocorre? Ao comparar a amplitude (diferença entre o máximo e o mínimo) do desempenho em diferentes tamanhos de conjunto de teste, o que você observa? Qual é a relação entre o tamanho do teste e a amplitude dos resultados?\n",
        "\n",
        "Se a variância dos resultados de acurácia for muito alta, o que isso pode indicar sobre o seu modelo ou sobre a forma como os dados estão sendo divididos?\n",
        "\n",
        "---\n",
        "\n",
        "*   R: Conforme o tamanho do conjunto de teste aumenta, a variância no desempenho do modelo tende a diminuir. Isso ocorre pois com mais amostras no conjunto de teste, a influência de cada observação se torna menor, aumentando a estabilidade do modelo. Quanto a amplitude do modelo, conforme aumentamos o tamanho do conjunto de teste, a amplitude tende a diminuir, aumentando a estabilidade. No caso de variâncias muito altas nos resultados, isso pode indicar um possível overfitting, bem como a representatividade precárias nos dados de treinamento. Também é possível verificar essa alta variância de acurácia em modelos muito sensíveis aos dados de entrada."
      ],
      "metadata": {
        "id": "eIRXrBjtLHVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Analisando o impacto do tamanho do conjunto de treino na avaliação de desempenho dos modelos\n",
        "\n"
      ],
      "metadata": {
        "id": "DV7YEZf_Eu39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Função para rodar o KNN com diferentes tamanhos de treino\n",
        "def run_knn_analysis(X, y, test_size=0.1, train_sizes=[0.1, 0.2, 0.3, 0.4, 0.50, 0.6, 0.7, 0.8], iterations=10):\n",
        "    results = {}\n",
        "\n",
        "    # Fixando o conjunto de teste\n",
        "    X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Criando o objeto de normalização\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_full)\n",
        "\n",
        "    # Normalizando o conjunto de teste\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    for train_size in train_sizes:\n",
        "        accuracies = []\n",
        "        for _ in range(iterations):\n",
        "            # Amostrando um conjunto de treino de tamanho variável\n",
        "            X_train_sample, _, y_train_sample, _ = train_test_split(\n",
        "                X_train_full, y_train_full, train_size=train_size, random_state=None\n",
        "            )\n",
        "\n",
        "            # Normalizando o conjunto de treino amostrado\n",
        "            X_train_sample = scaler.transform(X_train_sample)\n",
        "\n",
        "            # Treinar o kNN\n",
        "            knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "            knn_model.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "            # Classificação e avaliação no conjunto de teste fixo\n",
        "            y_pred_knn = knn_model.predict(X_test)\n",
        "            accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "        # Calculando estatísticas do desempenho\n",
        "        variance = np.var(accuracies)\n",
        "        amplitude = np.max(accuracies) - np.min(accuracies)\n",
        "        average = np.mean(accuracies)\n",
        "\n",
        "        results[train_size] = {\n",
        "            'accuracies': accuracies,\n",
        "            'variance': variance,\n",
        "            'amplitude': amplitude,\n",
        "            'average': average\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Exemplo de uso\n",
        "variances = []\n",
        "amplitudes = []\n",
        "averages = []\n",
        "train_sizes = [0.1, 0.2, 0.3, 0.4, 0.50, 0.6, 0.7, 0.8]\n",
        "\n",
        "results = run_knn_analysis(X, y)\n",
        "\n",
        "for train_size, metrics in results.items():\n",
        "    variances.append(metrics['variance'])\n",
        "    amplitudes.append(metrics['amplitude'])\n",
        "    averages.append(metrics['average'])\n",
        "\n",
        "# Gráfico de variância vs tamanho do conjunto de treino\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(train_sizes, variances, c='blue', label='Variância do Desempenho')\n",
        "plt.plot(train_sizes, variances, color='blue', linestyle='--')\n",
        "plt.xlabel('Proporção do Conjunto de Treino')\n",
        "plt.ylabel('Variância da Acurácia')\n",
        "plt.title('Variância da Acurácia em Função do Tamanho do Conjunto de Treino')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Gráfico de amplitude vs tamanho do conjunto de treino\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(train_sizes, amplitudes, c='red', label='Amplitude do Desempenho (Max - Min)')\n",
        "plt.plot(train_sizes, amplitudes, color='red', linestyle='--')\n",
        "plt.xlabel('Proporção do Conjunto de Treino')\n",
        "plt.ylabel('Amplitude da Acurácia')\n",
        "plt.title('Amplitude da Acurácia em Função do Tamanho do Conjunto de Treino')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Gráfico de média vs tamanho do conjunto de treino\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(train_sizes, averages, c='b', label='Média')\n",
        "plt.plot(train_sizes, averages, color='b', linestyle='--')\n",
        "plt.xlabel('Proporção do Conjunto de Treino')\n",
        "plt.ylabel('Média da Acurácia')\n",
        "plt.title('Média da Acurácia em Função do Tamanho do Conjunto de Treino')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Ff0C-mCup9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**>> Analise e Discuta:**\n",
        "\n",
        "Mantendo o conjunto de teste fixo, que mudança ou tendência observamos no desempenho dos modelos conforme mais dados de treino são utilizados? Como a amplitude (diferença entre o máximo e o mínimo) do desempenho varia com o tamanho do conjunto de treino? O que isso nos diz sobre a confiabilidade do modelo com tamanhos pequenos de conjunto de treino?\n",
        "\n",
        "---\n",
        "\n",
        "*   R: Embora no conjunto de dados observado a menor proporção de dados no conjunto de treino resultou em uma média de acurácia superior, isto não é o padrão que observamos ao analisar a maioria dos conjuntos de dados. Quando temos menos dados para treinar um determinado modelo, estamos limitando a sua capacidade de representação, o que implica diretamente na sua acurácia. Conforme aumentamos o conjunto de treino, percebemos a diminuição na amplitude e variância da acurácia, o que indica que o modelo está indo em direção a estabilidade de desempenho, garantindo maior confiabilidade para aplicar este modelo em dados ainda não observados."
      ],
      "metadata": {
        "id": "dCPtGfvgLS-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sumarize as suas análises e conclusões em um documento word ou PDF (inserindo as respectivas perguntas propostas), e envie no Moodle."
      ],
      "metadata": {
        "id": "T_7K8GN9a1A6"
      }
    }
  ]
}