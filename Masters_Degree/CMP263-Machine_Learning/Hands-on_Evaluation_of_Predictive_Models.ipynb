{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Programa de Pós-Graduação em Computação - INF/UFRGS**\n",
        "### Disciplina CMP263 - Aprendizagem de Máquina\n",
        "#### *Profa. Mariana Recamonde-Mendoza (mrmendoza@inf.ufrgs.br)*\n",
        "<br>\n",
        "\n",
        "---\n",
        "***Observação:*** *Este notebook é disponibilizado aos alunos como complemento às aulas síncronas e aos slides preparados pela professora. Desta forma, os principais conceitos são apresentados no material teórico fornecido. *\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0FA12O8Tpjmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "## **Tópico: Avaliação de Modelos Preditivos**\n",
        "\n",
        "<br>\n",
        "\n",
        "Até o momento trabalhamos com a avaliação de modelos preditivos utilizando a estratégia mais simples, de **Holdout** - uma simples divisão aleatória dos dados em conjuntos de treinamento e teste (Holdout de 2 vias) ou em conjuntos de treinamento, validação e teste (Holdout de 3 vias). No entanto, um treinamento e avaliação robustos de modelos preditivos demanda o uso de outras estratégias de divisão de dados, especialmente quando estamos trabalhando com um conjunto de dados de tamanho limitado. Dentre estas estratégias, destacamos o *k-fold cross-validation*.\n",
        "\n",
        "O *k-fold cross-validation* (ou validação cruzada k-fold) e suas variantes (como *leave-one-out cross-validation* e *nested cross-validation*) estabeleceram-se como métodos referência para avaliar modelos em Aprendizado de Máquina pois mitigam diversas limitações relacionadas ao uso de Holdout, como i) permitir avaliar o desempenho de modelos preditivos com variações de conjuntos de dados de treinamento/teste (e assim evitar que os resultados dependam de uma escolha aleatória particular de divisão de dados), e ii) permitir que toda instância no conjunto de dados seja usada uma vez para avaliação do modelo.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Objetivo deste notebook**: Explorar o uso de k-fold cross-validation para treinamento e avaliação de modelos preditivos, e otimização de hiperparâmetros.\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VDNPuCNO2tpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Diagnóstico de Câncer de Mama**\n",
        "\n",
        "Nesta atividade, vamos analisar o conjunto de dados relacionado ao diagnóstico de câncer de mama. Cada instância se refere ao exame de um(a) paciente. Os atributos são computados a partir de uma imagem digitalizada de material coletado de uma massa mamária através de uma punção aspirativa por agulha fina (PAAF). Por intermédio deste procedimento, é possível obter células de uma suspeita de lesão, que usualmente são analisadas com o auxílio de um microscópio pelo médico patologista. Os dados a serem utilizados definem um conjunto de atributos que descrevem as características dos núcleos celulares presentes na imagem, com o intuito de automatizar o processo de análise e definição do diagnóstico provável.\n",
        "\n",
        "Dez características foram analisadas para cada núcleo celular:\n",
        "\n",
        "*   raio (média das distâncias do centro aos pontos do perímetro)\n",
        "*   textura (desvio padrão dos valores de escala de cinza)\n",
        "*   perímetro\n",
        "*   área\n",
        "*   suavidade (variação local nos comprimentos dos raios)\n",
        "*   compacidade (perímetro^2 / área - 1,0)\n",
        "*   concavidade (gravidade das porções côncavas do contorno)\n",
        "*   pontos côncavos (número de porções côncavas do contorno)\n",
        "*   simetria\n",
        "*   dimensão fractal\n",
        "\n",
        "Para cada característica foram extraídas a média, o erro padrão e o pior (ou maior) valor, resultando em 30 atributos para cada exame. A última coluna, 'diagnosis', contém a classe verdadeira de cada instância, que pode ser M (maligno) ou B (benigno).\n",
        "\n"
      ],
      "metadata": {
        "id": "DbJNQfaM4ERT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jiutqCcGYYM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Carregando e inspecionando os dados\n",
        "\n",
        "Primeiramente, vamos carregar algumas bibliotecas importantes do Python e os dados a serem utilizados neste estudo. Os dados são disponibilizados através de um link, que também pode ser diretamente acessado pelos alunos."
      ],
      "metadata": {
        "id": "dbr-VwMq6OPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Carregando as bibliotecas necessárias\n",
        "# A primeira linha é incluída para gerar os gráficos logo abaixo dos comandos de plot\n",
        "%matplotlib inline\n",
        "import pandas as pd             # biblioteca para análise de dados\n",
        "import matplotlib.pyplot as plt # biblioteca para visualização de informações\n",
        "import seaborn as sns           # biblioteca para visualização de informações\n",
        "import numpy as np              # biblioteca para operações com arrays multidimensionais\n",
        "sns.set()\n",
        "\n",
        "## Bibliotecas para treinamento/avaliação de modelos\n",
        "from sklearn.model_selection import RepeatedKFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score, cross_val_predict\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "## Bibliotecas para converter variáveis categóricas (strings) para numéricas\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "sns.set()\n"
      ],
      "metadata": {
        "id": "2lyNg5Sluhbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Carregando os dados\n",
        "data = pd.read_table(\"https://drive.google.com/uc?export=view&id=1S-qqiA7cISZzRsLBmBoXyVYO5opY4WEa\")\n",
        "data.head()  # para visualizar apenas as 5 primeiras linhas\n"
      ],
      "metadata": {
        "id": "bPcnFsAB9kv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A coluna *'diagnosis'* contém a classificação de cada amostra referente ao tipo de tumor, se maligno (M) ou benigno (B). Vamos avaliar como as instâncias estão distribuídas entre as classes presentes no dataset."
      ],
      "metadata": {
        "id": "N1Jhj59hRhlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Distribuição do atributo alvo, 'diagnosis'\n",
        "plt.hist(data['diagnosis'])\n",
        "plt.title(\"Distribuição do atributo alvo - diagnosis\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4BWj00iDltyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Criando conjuntos de treino e teste para avaliação de modelos\n",
        "\n",
        "\n",
        "Antes de iniciar o treinamento do modelo, lembre-se que é recomendado sempre reservar uma porção dos dados para teste, a qual somente será utilizada para avaliação do modelo final (após todo o processo de treinamento e otimização de hiperparâmetros).\n",
        "\n",
        "Vamos fazer esta divisão, separando 20% para teste. Entretanto, primeiro precisamos dividir os dados entre atributos (X) e classe (y). Também iremos codificar os valores categóricos em inteiros a fim de ampliar as opções de algoritmos que podemos utilizar no treinamento dos modelos.\n",
        "\n"
      ],
      "metadata": {
        "id": "63nQ-E0jVQzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Separa o dataset em duas variáveis: os atributos/entradas (X) e a classe/saída (y)\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, 30].values\n",
        "\n",
        "## substitui 'B' por 0, 'M' por 1\n",
        "y = np.array([0 if y=='B' else 1 for y in y])"
      ],
      "metadata": {
        "id": "pd1ZSQRnXQq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Faz a divisão entre treino (80%) e teste (20%).\n",
        "## O conjunto de treino representa os dados que serão usados\n",
        "## ao longo do desenvolvimento do modelo\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,stratify=y,random_state=42)"
      ],
      "metadata": {
        "id": "eZbsoLfsXkoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Faz a normalização dos dados.\n",
        "## Para fins de uso ao longo de todo o notebook, faremos\n",
        "## separadamento entre treino e teste.\n",
        "## Conforme discutiremos ao longo do curso,\n",
        "## o conceito de 'Pipelines' pode ser usado para aprimorar essa solução.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler .transform(X_test)"
      ],
      "metadata": {
        "id": "ru7lAH6jtbUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "### Treinamento de modelos com k-fold cross-validation\n",
        "\n",
        "O scikit-learn possui amplo suporte para uso de k-fold cross-validation. Existem duas funções no scikit-learn que você pode usar para realizar a validação cruzada, a função [`cross_val_score`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) e a função [`cross_validate`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html). A função `cross_val_score` está no scikit-learn há muito tempo e tem uma interface muito simples, enquanto a função `cross_validate` foi adicionada posteriormente, é um pouco mais poderosa e oferece mais opções (como especificar múltiplas métricas para avaliação). No entanto, ambas têm uma interface muito semelhante e são fáceis de usar. Uma questão importante é que elas permitem especificar tanto o algoritmo de aprendizado (estimator) como detalhes da divisão de dados (número de folds, [estratégia de divisão](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators), etc.) Por padrão, ambas usam 5-fold CV.\n",
        "\n",
        "O K-fold cross-validation (K-fold CV) visa de certa forma 'substituir' uma simples divisão entre treino/validação para o desenvolvimento dos modelos. Assim, vamos aplicar o k-Fold CV na partição `X_train` usando uma árvore de decisão e um KNN (por enquanto, sem otimização de hiperparâmetros). Preparamos o procedimento de k-Fold CV antes da função a fim de gerar a mesma partição de treino/teste para cada fold no caso de comparar múltiplos algoritmos. Usamos a versão `StratifiedKFold` para gerar uma divisão estratificada em relação às classes (para regressão, ou para problemas bem balanceados, podemos usar `KFold`)"
      ],
      "metadata": {
        "id": "zuhzlay5bmQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Usando a função cross_val_score"
      ],
      "metadata": {
        "id": "giHHh_qvwWKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_5f = StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)\n",
        "\n",
        "## Avalia uma árvore de decisão com 5-fold CV\n",
        "clf_dt = DecisionTreeClassifier(max_depth=5,class_weight='balanced',random_state=42)\n",
        "scores_dt = cross_val_score(estimator=clf_dt, X=X_train, y=y_train,scoring='recall',cv=cv_5f)\n",
        "\n",
        "## Avalia um 5-NN com 5-fold CV\n",
        "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
        "scores_knn = cross_val_score(estimator=clf_knn, X=X_train, y=y_train,scoring='recall',cv=cv_5f)"
      ],
      "metadata": {
        "id": "fKLCOjBlfLrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores_dt)\n",
        "print(np.mean(scores_dt))\n",
        "print(np.std(scores_dt))"
      ],
      "metadata": {
        "id": "Wgaz5Gjzj65t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores_knn)\n",
        "print(np.mean(scores_knn))\n",
        "print(np.std(scores_knn))"
      ],
      "metadata": {
        "id": "56fzMJlMtn3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results=[]\n",
        "results.append(scores_dt)\n",
        "results.append(scores_knn)\n",
        "plt.boxplot(results, tick_labels=['DT','KNN'], showmeans=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y-FHXNMYu3j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função [`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) tem uma interface similar a `cross_val_score`, mas retorna a predição de cada instância quando a mesma foi alocada ao conjunto de teste."
      ],
      "metadata": {
        "id": "gvaPb3hMvZzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_dt = cross_val_predict(estimator=clf_dt, X=X_train, y=y_train,cv=cv_5f)#,method='predict_proba') ##descomente para retornar as probabilidades preditas\n",
        "print(predict_dt)"
      ],
      "metadata": {
        "id": "xfuJ80hqvt-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Usando a função cross_validate"
      ],
      "metadata": {
        "id": "mAAxDU1ZwdZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função permite estabelecer um conjunto de métricas de avaliação no parâmetro [scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).\n",
        "\n",
        "Vamos utilizar para fins de exemplo, Recall, Precisão e Acurácia.\n"
      ],
      "metadata": {
        "id": "7gFMnrinw4n_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = ['recall','precision','accuracy']"
      ],
      "metadata": {
        "id": "g6QMWaPvwcjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Avalia uma árvore de decisão com 5-fold CV\n",
        "scores_dt2 = cross_validate(estimator=clf_dt, X=X_train, y=y_train,scoring=scoring,cv=cv_5f)\n",
        "\n",
        "## Avalia um 5-NN com 5-fold CV\n",
        "scores_knn2 = cross_validate(estimator=clf_knn, X=X_train, y=y_train,scoring=scoring,cv=cv_5f)"
      ],
      "metadata": {
        "id": "8Mi2nOKqxpOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_dt2_df = pd.DataFrame(scores_dt2, columns=scores_dt2.keys())\n",
        "scores_dt2_df"
      ],
      "metadata": {
        "id": "uIWWL6ylyAJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(scores_dt2_df[[\"test_recall\",\"test_precision\",\"test_accuracy\"]],tick_labels=['Recall','Precision','Accuracy'],showmeans=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P95lqbzE7sTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_knn2_df = pd.DataFrame(scores_knn2, columns=scores_dt2.keys())\n",
        "scores_knn2_df"
      ],
      "metadata": {
        "id": "uJZAbm-AynA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(scores_knn2_df[[\"test_recall\",\"test_precision\",\"test_accuracy\"]],tick_labels=['Recall','Precision','Accuracy'],showmeans=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u8qENtxt8krh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Usando o Repeated KFold\n",
        "Abaixo vamos realizar o treinamento dos dois modelos, baseado em árvores de decisão e baseado em KNN, utilizando o RepeatedKFold. O processo é exatamente igual ao que foi feito anteriormente, a diferença é que agora obtemos 15 estimativas de desempenho para cada modelo."
      ],
      "metadata": {
        "id": "97EA4Zpyxh-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repcv_5f = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
        "\n",
        "## Avalia uma árvore de decisão com 5-fold CV repetido 3 vezes\n",
        "scores_dt_rep = cross_validate(estimator=clf_dt, X=X_train, y=y_train,scoring=scoring,cv=repcv_5f)\n",
        "\n",
        "## Avalia um 5-NN  com 5-fold CV repetido 3 vezes\n",
        "scores_knn_rep = cross_validate(estimator=clf_knn, X=X_train, y=y_train,scoring=scoring,cv=repcv_5f)"
      ],
      "metadata": {
        "id": "WOj_0vpI-wGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_dt2rep_df = pd.DataFrame(scores_dt_rep, columns=scores_dt_rep.keys())\n",
        "scores_dt2rep_df"
      ],
      "metadata": {
        "id": "QluEETob936W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(scores_dt2rep_df[[\"test_recall\",\"test_precision\",\"test_accuracy\"]],tick_labels=['Recall','Precision','Accuracy'],showmeans=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mn_PhW_C-guM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_knn2rep_df = pd.DataFrame(scores_knn_rep, columns=scores_knn_rep.keys())\n",
        "scores_knn2rep_df"
      ],
      "metadata": {
        "id": "b1sTmdIn-0tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(scores_knn2rep_df[[\"test_recall\",\"test_precision\",\"test_accuracy\"]],tick_labels=['Recall','Precision','Accuracy'],showmeans=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q9KXW37T-_G0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pelo critério de Recall, o modelo de Árvores de decisão obteve os melhores resultados, com mediana e média mais altas. Por outro lado, o KNN possui melhor precisão e uma maior acurácia média.\n",
        "\n",
        "A escolha do melhor modelo não é direta ou trivial. No domínio médico, a sensibilidade (recall) é uma métrica muito relevante. Assim, o modelo de  Árvores de decisão poderia ser escolhido dentre os dois analisados  para treinar um modelo a partir de todos os dados de treinamento, e avaliar seu desempenho final nos dados de teste. Este desempenho final é a estimativa do poder preditivo que poderíamos obter caso este modelo seja aplicado para auxiliar no diagnóstico precoce de diabetes."
      ],
      "metadata": {
        "id": "AYRdH-ZdzQ1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.metrics import roc_curve, auc\n",
        "dt_final = clf_dt.fit(X_train,y_train)\n",
        "y_predProba_dt = dt_final.predict_proba(X_test)\n",
        "y_pred_dt = dt_final.predict(X_test)\n",
        "\n",
        "print(metrics.recall_score(y_test,y_pred_dt))\n",
        "print(metrics.precision_score(y_test,y_pred_dt))\n",
        "print(metrics.accuracy_score(y_test,y_pred_dt))"
      ],
      "metadata": {
        "id": "4zhAl7CspdSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predProba_dt"
      ],
      "metadata": {
        "id": "MYaLc7E7vkpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Otimização de hiperparâmetros com GridSearch e Nested Cross-validation"
      ],
      "metadata": {
        "id": "GhE3zGCb_OcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O sklearn disponibiliza a função `GridSearchCV`, que permite realizar a otimização de hiperparâmetros de forma prática usando k-fold cross-validation. A chamada da função é muito simples:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "search = GridSearchCV(estimator, param_grid, scoring='recall', n_jobs=1, cv=5, refit=True)\n",
        "```\n",
        "\n",
        "A função, conforme chamada acima, utiliza um modelo (`estimator`) para explorar as combinações de valores de hiperparâmetros definidos em `param_grid,` através de um 5-fold cross-validation (determinado por `cv`) e escolhe o melhor modelo a partir da métrica de Recall(também configurável). A opção `refit=True` define que após determinar a melhor configuração de hiperparâmetros, a mesma será utilizada para retreinar um modelo com todos os dados utilizados no processo de GridSearch com CV.\n",
        "\n"
      ],
      "metadata": {
        "id": "g0Xk_oDpgKqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A validação cruzada aninhada (nested cross-validation) é frequentemente usada para treinar um modelo no qual os hiperparâmetros também precisam ser otimizados. A seleção de modelo sem CV aninhado usa os mesmos dados para ajustar os hiperparâmetros do modelo e avaliar o desempenho do modelo. As informações podem, portanto, “vazar” para o modelo, que acaba se sobreajustando aos dados. O resultado deste vazamento pode ser uma avaliação excessivamente otimista. A magnitude desse efeito depende principalmente do tamanho do conjunto de dados e da estabilidade do modelo.\n",
        "\n",
        "Na célula abaixo, vamos executar o k-fold cross-validation e o nested cross-validation, treinando uma árvore de decisão com pré-poda. O hiperparâmetro a ser otimizado é o `max_depth`. Para os resultados mostrados abaixo, o desempenho refere-se sempre ao melhor valor de hiperparâmetro obtido a cada iteração do GridSearch."
      ],
      "metadata": {
        "id": "Jqm0cQX2wSaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Adaptado de: https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Número de execuções da validação cruzada (aninhada/não aninhada)\n",
        "NUM_TRIALS = 30\n",
        "\n",
        "# Grid de hiperparâmetros para otimização\n",
        "param_grid = {\"max_depth\": [1,2,3,4,5,6,7]}\n",
        "\n",
        "# Uso de uma árvore de decisão como algoritmo de aprendizado\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "# Arrays para armazenar os scores de cada abordagem\n",
        "non_nested_scores = np.zeros(NUM_TRIALS)\n",
        "nested_scores = np.zeros(NUM_TRIALS)\n",
        "\n",
        "# Loop para múltiplas execuções, cada qual com um random_state distinto\n",
        "for i in range(NUM_TRIALS):\n",
        "\n",
        "    # Definir estratégias de validação cruzada para o loop interno (inner) e para\n",
        "    # o loop externo (outer). As escolhas podem ser diferentes. Aqui, optamos por\n",
        "    # usar StratifiedKFold em ambas.\n",
        "    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
        "    outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
        "\n",
        "    # GridSearch e avaliação dos modelos na abordagem de k-fold cross-validation padrão\n",
        "    # (sem aninhamento) - avalia os modelos com os mesmos dados usados para selecionar hiperparâmetros\n",
        "    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=outer_cv) ## sem aninhamento - desempenho com melhores hiperparâmetros\n",
        "    clf.fit(X_train, y_train)\n",
        "    non_nested_scores[i] = clf.best_score_\n",
        "\n",
        "    # GridSearch e avaliação dos modelos na abordagem de nested k-fold cross-validation\n",
        "    clf = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_cv, refit=True) ##inner CV - melhores hiperparâmetros\n",
        "    nested_score = cross_val_score(clf, X=X_train, y=y_train, cv=outer_cv) ##outer CV - desempenho com melhores hiperparâmetros (do inner)\n",
        "    nested_scores[i] = nested_score.mean()\n",
        "\n",
        "## Calcula a diferença de scores entre as abordagens\n",
        "score_difference = non_nested_scores - nested_scores\n",
        "\n",
        "print(\n",
        "    \"Average difference of {:6f} with std. dev. of {:6f}.\".format(\n",
        "        score_difference.mean(), score_difference.std()\n",
        "    )\n",
        ")\n",
        "\n",
        "# Plotar um gráfico com os scores obtidos e com a diferença entre eles\n",
        "# em cada iteração\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(211)\n",
        "(non_nested_scores_line,) = plt.plot(non_nested_scores, color=\"r\")\n",
        "(nested_line,) = plt.plot(nested_scores, color=\"b\")\n",
        "plt.ylabel(\"score\", fontsize=\"14\")\n",
        "plt.legend(\n",
        "    [non_nested_scores_line, nested_line],\n",
        "    [\"Non-Nested CV\", \"Nested CV\"],\n",
        "    bbox_to_anchor=(0, 0.4, 0.5, 0),\n",
        ")\n",
        "plt.title(\n",
        "    \"Non-Nested and Nested Cross Validation on Breast Cancer Dataset\",\n",
        "    x=0.5,\n",
        "    y=1.1,\n",
        "    fontsize=\"15\",\n",
        ")\n",
        "\n",
        "# Plot bar chart of the difference.\n",
        "plt.subplot(212)\n",
        "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
        "plt.xlabel(\"Individual Trial #\")\n",
        "plt.legend(\n",
        "    [difference_plot],\n",
        "    [\"Non-Nested CV - Nested CV Score\"],\n",
        "    bbox_to_anchor=(0, 1, 0.8, 0),\n",
        ")\n",
        "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KnDkK0q9w6v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A célula a seguir faz a otimização de hiperparâmetros com nested cross-validation para o algoritmo de árvore de decisão."
      ],
      "metadata": {
        "id": "SZGlkAb1do37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define o modelo\n",
        "model = DecisionTreeClassifier()\n",
        "# define o espaço de busca de hiperparâmetros\n",
        "param_grid = dict()\n",
        "param_grid['max_depth'] = [3,5,7,None]\n",
        "param_grid['min_samples_split'] = [5,15,30,None]\n",
        "\n",
        "### loop interno ####\n",
        "# configura o loop interno do nested cross-validation\n",
        "cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# define a estratégia de busca dos melhores hiperparâmetros (baseado em recall)\n",
        "search = GridSearchCV(model, param_grid, scoring='recall', n_jobs=1, cv=cv_inner, refit=True)\n",
        "### loop interno ####\n",
        "\n",
        "### loop externo ####\n",
        "# configura o loop externo do nested cross-validatiion\n",
        "cv_outer = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# executa o nested cross-validation\n",
        "output_ncv = cross_validate(search, X_train, y_train, scoring=scoring, cv=cv_outer, n_jobs=-1,return_estimator=True, return_train_score=True)\n",
        "\n",
        "# reporta os resultados\n",
        "pd.DataFrame(output_ncv)"
      ],
      "metadata": {
        "id": "yEoq1FbXgPje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos avaliar os resultados do processo de nested cross-validation observando a variação de desempenho ao longo das múltiplas execuções e os melhores valores de hiperparâmetros selecionados em cada iteração. Cabe salientar que esta análise é feita com base no número de repetições do outer cross-validation (neste caso, configurado com 10 folds)"
      ],
      "metadata": {
        "id": "ZYLpwXhXpZuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Análise de recall\n",
        "mean_val_score = output_ncv['test_recall'].mean()\n",
        "\n",
        "print('nested_train_scores: ', output_ncv['train_recall'])\n",
        "print('nested_val_scores:   ', output_ncv['test_recall'])\n",
        "print('mean score:            {0:.2f}'.format(mean_val_score))"
      ],
      "metadata": {
        "id": "_RuqlTwwbP4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Análise de precisão\n",
        "mean_val_score = output_ncv['test_precision'].mean()\n",
        "\n",
        "print('nested_train_scores: ', output_ncv['train_precision'])\n",
        "print('nested_val_scores:   ', output_ncv['test_precision'])\n",
        "print('mean score:            {0:.2f}'.format(mean_val_score))"
      ],
      "metadata": {
        "id": "yjLzB0LGuMLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Quais os melhores valores de hiperparâmetros de acordo com o nested Cross_validation?\n",
        "[x.best_params_ for x in output_ncv['estimator']]"
      ],
      "metadata": {
        "id": "bLD6dnSqbeoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O conhecimento a respeito dos melhores hiperparâmetros ao longo do nested cross-validation pode guiar nossa decisão sobre que modelos (algoritmos e configuração de hiperparâmetros) podemos utilizar para gerar o modelo final. Este modelo final seria obtido treinando um modelo com estas configurações sobre todo o conjunto de dados usado no processo de avaliação.\n",
        "\n"
      ],
      "metadata": {
        "id": "jNjBQSnlpwlN"
      }
    }
  ]
}